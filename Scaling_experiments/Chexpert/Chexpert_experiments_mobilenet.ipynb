{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(6)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../prepare_data.py\n",
    "%run ../../architectures.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, valid_dataset = get_chexpert_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 256, 256]), torch.Size([32, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MobileNet(num_classes=5, width_mult=1.0, depth_mult=1.0).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2230277"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 8.38 s, total: 1min 34s\n",
      "Wall time: 1min 35s\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%time\n",
    "lrs, losses = LR_range_finder(model, train_loader, \n",
    "                              loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                              binary=False, lr_high=0.05)\n",
    "plot_lr(lrs, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [1.0, 0.75, 0.5, 0.25]\n",
    "depths = [1.0, 0.7, 0.6, 0.5, 0.3, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width multiplier - 1.000 depth multiplier - 1.000\n",
      "train_loss 0.427 val_loss 0.435 val_auc_score 0.569\n",
      "----End of step 0:01:44.103960\n",
      "train_loss 0.420 val_loss 0.424 val_auc_score 0.611\n",
      "----End of step 0:01:44.294860\n",
      "train_loss 0.413 val_loss 0.420 val_auc_score 0.630\n",
      "----End of step 0:01:44.873700\n",
      "train_loss 0.406 val_loss 0.416 val_auc_score 0.633\n",
      "----End of step 0:01:45.652851\n",
      "train_loss 0.400 val_loss 0.418 val_auc_score 0.645\n",
      "----End of step 0:01:45.445690\n",
      "train_loss 0.395 val_loss 0.411 val_auc_score 0.659\n",
      "----End of step 0:01:45.237801\n",
      "train_loss 0.390 val_loss 0.414 val_auc_score 0.649\n",
      "----End of step 0:01:45.163446\n",
      "train_loss 0.386 val_loss 0.409 val_auc_score 0.655\n",
      "----End of step 0:01:45.195314\n",
      "train_loss 0.382 val_loss 0.397 val_auc_score 0.687\n",
      "----End of step 0:01:45.326736\n",
      "train_loss 0.378 val_loss 0.397 val_auc_score 0.685\n",
      "----End of step 0:01:45.162718\n",
      "train_loss 0.376 val_loss 0.392 val_auc_score 0.692\n",
      "----End of step 0:01:45.663486\n",
      "train_loss 0.373 val_loss 0.394 val_auc_score 0.690\n",
      "----End of step 0:01:45.621374\n",
      "train_loss 0.371 val_loss 0.391 val_auc_score 0.697\n",
      "----End of step 0:01:47.758128\n",
      "train_loss 0.370 val_loss 0.391 val_auc_score 0.697\n",
      "----End of step 0:01:46.352399\n",
      "train_loss 0.369 val_loss 0.391 val_auc_score 0.697\n",
      "----End of step 0:01:46.164389\n",
      "\n",
      "width multiplier - 0.750 depth multiplier - 1.000\n",
      "train_loss 0.430 val_loss 0.440 val_auc_score 0.564\n",
      "----End of step 0:01:44.569184\n",
      "train_loss 0.420 val_loss 0.426 val_auc_score 0.605\n",
      "----End of step 0:01:42.818115\n",
      "train_loss 0.414 val_loss 0.428 val_auc_score 0.606\n",
      "----End of step 0:01:46.110706\n",
      "train_loss 0.409 val_loss 0.419 val_auc_score 0.633\n",
      "----End of step 0:01:43.100173\n",
      "train_loss 0.403 val_loss 0.418 val_auc_score 0.650\n",
      "----End of step 0:01:47.462976\n",
      "train_loss 0.399 val_loss 0.410 val_auc_score 0.659\n",
      "----End of step 0:01:44.674238\n",
      "train_loss 0.394 val_loss 0.407 val_auc_score 0.661\n",
      "----End of step 0:01:48.867281\n",
      "train_loss 0.391 val_loss 0.404 val_auc_score 0.671\n",
      "----End of step 0:01:41.547098\n",
      "train_loss 0.387 val_loss 0.406 val_auc_score 0.674\n",
      "----End of step 0:01:46.082002\n",
      "train_loss 0.384 val_loss 0.404 val_auc_score 0.668\n",
      "----End of step 0:01:44.178839\n",
      "train_loss 0.381 val_loss 0.399 val_auc_score 0.681\n",
      "----End of step 0:01:44.359047\n",
      "train_loss 0.379 val_loss 0.396 val_auc_score 0.689\n",
      "----End of step 0:01:44.294341\n",
      "train_loss 0.377 val_loss 0.398 val_auc_score 0.685\n",
      "----End of step 0:01:45.114411\n",
      "train_loss 0.375 val_loss 0.395 val_auc_score 0.689\n",
      "----End of step 0:01:43.035791\n",
      "train_loss 0.374 val_loss 0.396 val_auc_score 0.689\n",
      "----End of step 0:01:43.174532\n",
      "\n",
      "width multiplier - 0.500 depth multiplier - 1.000\n",
      "train_loss 0.427 val_loss 0.433 val_auc_score 0.579\n",
      "----End of step 0:01:42.895144\n",
      "train_loss 0.420 val_loss 0.433 val_auc_score 0.598\n",
      "----End of step 0:01:43.147689\n",
      "train_loss 0.416 val_loss 0.427 val_auc_score 0.617\n",
      "----End of step 0:01:46.164656\n",
      "train_loss 0.409 val_loss 0.422 val_auc_score 0.611\n",
      "----End of step 0:01:44.600322\n",
      "train_loss 0.403 val_loss 0.421 val_auc_score 0.640\n",
      "----End of step 0:01:46.219238\n",
      "train_loss 0.400 val_loss 0.413 val_auc_score 0.644\n",
      "----End of step 0:01:43.839204\n",
      "train_loss 0.396 val_loss 0.414 val_auc_score 0.652\n",
      "----End of step 0:01:44.680530\n",
      "train_loss 0.392 val_loss 0.408 val_auc_score 0.654\n",
      "----End of step 0:01:47.716249\n",
      "train_loss 0.390 val_loss 0.406 val_auc_score 0.657\n",
      "----End of step 0:01:46.185556\n",
      "train_loss 0.387 val_loss 0.417 val_auc_score 0.646\n",
      "----End of step 0:01:44.718313\n",
      "train_loss 0.385 val_loss 0.407 val_auc_score 0.662\n",
      "----End of step 0:01:43.554633\n",
      "train_loss 0.383 val_loss 0.402 val_auc_score 0.674\n",
      "----End of step 0:01:44.161145\n",
      "train_loss 0.381 val_loss 0.403 val_auc_score 0.669\n",
      "----End of step 0:01:44.622862\n",
      "train_loss 0.381 val_loss 0.403 val_auc_score 0.671\n",
      "----End of step 0:01:43.443204\n",
      "train_loss 0.380 val_loss 0.404 val_auc_score 0.670\n",
      "----End of step 0:01:45.417707\n",
      "\n",
      "width multiplier - 0.250 depth multiplier - 1.000\n",
      "train_loss 0.430 val_loss 0.438 val_auc_score 0.543\n",
      "----End of step 0:01:43.644947\n",
      "train_loss 0.428 val_loss 0.438 val_auc_score 0.566\n",
      "----End of step 0:01:44.133509\n",
      "train_loss 0.426 val_loss 0.437 val_auc_score 0.580\n",
      "----End of step 0:01:43.140630\n",
      "train_loss 0.420 val_loss 0.437 val_auc_score 0.588\n",
      "----End of step 0:01:42.560319\n",
      "train_loss 0.416 val_loss 0.425 val_auc_score 0.609\n",
      "----End of step 0:01:43.054327\n",
      "train_loss 0.412 val_loss 0.424 val_auc_score 0.618\n",
      "----End of step 0:01:42.867230\n",
      "train_loss 0.409 val_loss 0.424 val_auc_score 0.626\n",
      "----End of step 0:01:48.925002\n",
      "train_loss 0.406 val_loss 0.424 val_auc_score 0.632\n",
      "----End of step 0:01:43.884069\n",
      "train_loss 0.403 val_loss 0.417 val_auc_score 0.635\n",
      "----End of step 0:01:44.848252\n",
      "train_loss 0.401 val_loss 0.416 val_auc_score 0.644\n",
      "----End of step 0:01:45.859662\n",
      "train_loss 0.399 val_loss 0.415 val_auc_score 0.645\n",
      "----End of step 0:01:45.033280\n",
      "train_loss 0.398 val_loss 0.413 val_auc_score 0.647\n",
      "----End of step 0:01:43.182525\n",
      "train_loss 0.397 val_loss 0.413 val_auc_score 0.648\n",
      "----End of step 0:01:45.519096\n",
      "train_loss 0.396 val_loss 0.413 val_auc_score 0.650\n",
      "----End of step 0:01:43.201886\n",
      "train_loss 0.396 val_loss 0.413 val_auc_score 0.650\n",
      "----End of step 0:01:45.232095\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "d = 1.0\n",
    "\n",
    "for w in widths:\n",
    "#     for d in depths:\n",
    "    print('width multiplier - %.3f depth multiplier - %.3f' % (w, d))\n",
    "    model = MobileNet(num_classes=5,width_mult=w, depth_mult=d).cuda()\n",
    "    p = sum(p.numel() for p in model.parameters())\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    data.append([w, d, score, p, t])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  1.0,\n",
       "  0.6971991207952705,\n",
       "  2230277,\n",
       "  datetime.timedelta(seconds=106, microseconds=164389)],\n",
       " [0.75,\n",
       "  1.0,\n",
       "  0.6886364433978219,\n",
       "  1353373,\n",
       "  datetime.timedelta(seconds=103, microseconds=174532)],\n",
       " [0.5,\n",
       "  1.0,\n",
       "  0.6702295864375458,\n",
       "  690853,\n",
       "  datetime.timedelta(seconds=105, microseconds=417707)],\n",
       " [0.25,\n",
       "  1.0,\n",
       "  0.6500565009921415,\n",
       "  242717,\n",
       "  datetime.timedelta(seconds=105, microseconds=232095)]]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width multiplier - 1.000 depth multiplier - 0.700\n",
      "train_loss 0.427 val_loss 0.438 val_auc_score 0.577\n",
      "----End of step 0:01:40.933116\n",
      "train_loss 0.416 val_loss 0.428 val_auc_score 0.611\n",
      "----End of step 0:01:41.279703\n",
      "train_loss 0.410 val_loss 0.424 val_auc_score 0.625\n",
      "----End of step 0:01:43.538065\n",
      "train_loss 0.405 val_loss 0.415 val_auc_score 0.640\n",
      "----End of step 0:01:42.085308\n",
      "train_loss 0.399 val_loss 0.410 val_auc_score 0.657\n",
      "----End of step 0:01:44.114330\n",
      "train_loss 0.394 val_loss 0.408 val_auc_score 0.663\n",
      "----End of step 0:01:43.446975\n",
      "train_loss 0.390 val_loss 0.406 val_auc_score 0.659\n",
      "----End of step 0:01:43.677292\n",
      "train_loss 0.386 val_loss 0.405 val_auc_score 0.671\n",
      "----End of step 0:01:44.038716\n",
      "train_loss 0.382 val_loss 0.401 val_auc_score 0.678\n",
      "----End of step 0:01:45.801393\n",
      "train_loss 0.378 val_loss 0.394 val_auc_score 0.691\n",
      "----End of step 0:01:49.139231\n",
      "train_loss 0.376 val_loss 0.397 val_auc_score 0.690\n",
      "----End of step 0:01:52.244221\n",
      "train_loss 0.374 val_loss 0.393 val_auc_score 0.691\n",
      "----End of step 0:01:55.345061\n",
      "train_loss 0.372 val_loss 0.392 val_auc_score 0.697\n",
      "----End of step 0:01:54.395514\n",
      "train_loss 0.370 val_loss 0.393 val_auc_score 0.696\n",
      "----End of step 0:01:52.945878\n",
      "train_loss 0.370 val_loss 0.392 val_auc_score 0.697\n",
      "----End of step 0:01:54.469143\n",
      "\n",
      "width multiplier - 0.750 depth multiplier - 0.700\n",
      "train_loss 0.429 val_loss 0.446 val_auc_score 0.569\n",
      "----End of step 0:01:52.071797\n",
      "train_loss 0.420 val_loss 0.428 val_auc_score 0.604\n",
      "----End of step 0:01:56.434270\n",
      "train_loss 0.414 val_loss 0.425 val_auc_score 0.610\n",
      "----End of step 0:01:50.083994\n",
      "train_loss 0.408 val_loss 0.420 val_auc_score 0.631\n",
      "----End of step 0:01:43.865855\n",
      "train_loss 0.402 val_loss 0.414 val_auc_score 0.648\n",
      "----End of step 0:01:46.206683\n",
      "train_loss 0.396 val_loss 0.408 val_auc_score 0.661\n",
      "----End of step 0:01:45.954070\n",
      "train_loss 0.392 val_loss 0.407 val_auc_score 0.670\n",
      "----End of step 0:01:47.721759\n",
      "train_loss 0.388 val_loss 0.403 val_auc_score 0.671\n",
      "----End of step 0:01:46.302842\n",
      "train_loss 0.384 val_loss 0.406 val_auc_score 0.671\n",
      "----End of step 0:01:46.682532\n",
      "train_loss 0.382 val_loss 0.403 val_auc_score 0.678\n",
      "----End of step 0:01:42.763944\n",
      "train_loss 0.380 val_loss 0.399 val_auc_score 0.683\n",
      "----End of step 0:01:44.582860\n",
      "train_loss 0.377 val_loss 0.398 val_auc_score 0.684\n",
      "----End of step 0:01:45.028596\n",
      "train_loss 0.375 val_loss 0.396 val_auc_score 0.686\n",
      "----End of step 0:01:47.666247\n",
      "train_loss 0.374 val_loss 0.394 val_auc_score 0.689\n",
      "----End of step 0:01:46.432551\n",
      "train_loss 0.374 val_loss 0.394 val_auc_score 0.689\n",
      "----End of step 0:01:45.626181\n",
      "\n",
      "width multiplier - 0.500 depth multiplier - 0.700\n",
      "train_loss 0.430 val_loss 0.441 val_auc_score 0.546\n",
      "----End of step 0:01:46.254622\n",
      "train_loss 0.423 val_loss 0.448 val_auc_score 0.588\n",
      "----End of step 0:01:44.859914\n",
      "train_loss 0.418 val_loss 0.430 val_auc_score 0.597\n",
      "----End of step 0:01:47.508653\n",
      "train_loss 0.410 val_loss 0.422 val_auc_score 0.623\n",
      "----End of step 0:01:44.757391\n",
      "train_loss 0.406 val_loss 0.417 val_auc_score 0.635\n",
      "----End of step 0:01:45.458162\n",
      "train_loss 0.402 val_loss 0.417 val_auc_score 0.640\n",
      "----End of step 0:01:46.695910\n",
      "train_loss 0.398 val_loss 0.416 val_auc_score 0.657\n",
      "----End of step 0:01:45.182848\n",
      "train_loss 0.394 val_loss 0.416 val_auc_score 0.657\n",
      "----End of step 0:01:47.147802\n",
      "train_loss 0.391 val_loss 0.412 val_auc_score 0.666\n",
      "----End of step 0:01:45.439676\n",
      "train_loss 0.388 val_loss 0.406 val_auc_score 0.666\n",
      "----End of step 0:01:47.004568\n",
      "train_loss 0.386 val_loss 0.407 val_auc_score 0.671\n",
      "----End of step 0:01:46.474129\n",
      "train_loss 0.383 val_loss 0.403 val_auc_score 0.676\n",
      "----End of step 0:01:46.046390\n",
      "train_loss 0.382 val_loss 0.406 val_auc_score 0.675\n",
      "----End of step 0:01:48.805072\n",
      "train_loss 0.381 val_loss 0.404 val_auc_score 0.676\n",
      "----End of step 0:01:45.297170\n",
      "train_loss 0.380 val_loss 0.404 val_auc_score 0.676\n",
      "----End of step 0:01:47.715770\n",
      "\n",
      "width multiplier - 0.250 depth multiplier - 0.700\n",
      "train_loss 0.429 val_loss 0.436 val_auc_score 0.558\n",
      "----End of step 0:01:47.893970\n",
      "train_loss 0.425 val_loss 0.434 val_auc_score 0.574\n",
      "----End of step 0:01:46.449684\n",
      "train_loss 0.422 val_loss 0.432 val_auc_score 0.593\n",
      "----End of step 0:01:44.875743\n",
      "train_loss 0.417 val_loss 0.432 val_auc_score 0.600\n",
      "----End of step 0:01:45.267066\n",
      "train_loss 0.413 val_loss 0.427 val_auc_score 0.611\n",
      "----End of step 0:01:46.309215\n",
      "train_loss 0.411 val_loss 0.423 val_auc_score 0.620\n",
      "----End of step 0:01:47.414960\n",
      "train_loss 0.409 val_loss 0.419 val_auc_score 0.628\n",
      "----End of step 0:01:44.538209\n",
      "train_loss 0.406 val_loss 0.418 val_auc_score 0.637\n",
      "----End of step 0:01:43.819701\n",
      "train_loss 0.404 val_loss 0.414 val_auc_score 0.642\n",
      "----End of step 0:01:47.590434\n",
      "train_loss 0.402 val_loss 0.413 val_auc_score 0.648\n",
      "----End of step 0:01:48.733012\n",
      "train_loss 0.400 val_loss 0.412 val_auc_score 0.651\n",
      "----End of step 0:01:44.285871\n",
      "train_loss 0.398 val_loss 0.411 val_auc_score 0.653\n",
      "----End of step 0:01:47.092630\n",
      "train_loss 0.397 val_loss 0.411 val_auc_score 0.653\n",
      "----End of step 0:01:44.205922\n",
      "train_loss 0.396 val_loss 0.411 val_auc_score 0.653\n",
      "----End of step 0:01:44.846774\n",
      "train_loss 0.396 val_loss 0.410 val_auc_score 0.653\n",
      "----End of step 0:01:45.811608\n",
      "\n"
     ]
    }
   ],
   "source": [
    "d = 0.7\n",
    "\n",
    "for w in widths:\n",
    "#     for d in depths:\n",
    "    print('width multiplier - %.3f depth multiplier - %.3f' % (w, d))\n",
    "    model = MobileNet(num_classes=5,width_mult=w, depth_mult=d).cuda()\n",
    "    p = sum(p.numel() for p in model.parameters())\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    data.append([w, d, score, p, t])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1.0,\n",
       "  1.0,\n",
       "  0.6971991207952705,\n",
       "  2230277,\n",
       "  datetime.timedelta(seconds=106, microseconds=164389)],\n",
       " [0.75,\n",
       "  1.0,\n",
       "  0.6886364433978219,\n",
       "  1353373,\n",
       "  datetime.timedelta(seconds=103, microseconds=174532)],\n",
       " [0.5,\n",
       "  1.0,\n",
       "  0.6702295864375458,\n",
       "  690853,\n",
       "  datetime.timedelta(seconds=105, microseconds=417707)],\n",
       " [0.25,\n",
       "  1.0,\n",
       "  0.6500565009921415,\n",
       "  242717,\n",
       "  datetime.timedelta(seconds=105, microseconds=232095)],\n",
       " [1.0,\n",
       "  0.7,\n",
       "  0.6966568743445967,\n",
       "  2176005,\n",
       "  datetime.timedelta(seconds=114, microseconds=469143)],\n",
       " [0.75,\n",
       "  0.7,\n",
       "  0.6890028684475105,\n",
       "  1321885,\n",
       "  datetime.timedelta(seconds=105, microseconds=626181)],\n",
       " [0.5,\n",
       "  0.7,\n",
       "  0.6762539552376621,\n",
       "  676005,\n",
       "  datetime.timedelta(seconds=107, microseconds=715770)],\n",
       " [0.25,\n",
       "  0.7,\n",
       "  0.6534971727047003,\n",
       "  238365,\n",
       "  datetime.timedelta(seconds=105, microseconds=811608)]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width multiplier - 1.000 depth multiplier - 0.600\n",
      "train_loss 0.425 val_loss 0.433 val_auc_score 0.588\n",
      "----End of step 0:01:31.034952\n",
      "train_loss 0.417 val_loss 0.426 val_auc_score 0.591\n",
      "----End of step 0:01:31.582724\n",
      "train_loss 0.411 val_loss 0.421 val_auc_score 0.625\n",
      "----End of step 0:01:33.112747\n",
      "train_loss 0.404 val_loss 0.411 val_auc_score 0.647\n",
      "----End of step 0:01:34.136000\n",
      "train_loss 0.398 val_loss 0.415 val_auc_score 0.641\n",
      "----End of step 0:01:33.982062\n",
      "train_loss 0.393 val_loss 0.412 val_auc_score 0.661\n",
      "----End of step 0:01:32.858315\n",
      "train_loss 0.389 val_loss 0.403 val_auc_score 0.672\n",
      "----End of step 0:01:33.912574\n",
      "train_loss 0.386 val_loss 0.409 val_auc_score 0.662\n",
      "----End of step 0:01:34.895450\n"
     ]
    }
   ],
   "source": [
    "d = 0.6\n",
    "\n",
    "for w in widths:\n",
    "#     for d in depths:\n",
    "    print('width multiplier - %.3f depth multiplier - %.3f' % (w, d))\n",
    "    model = MobileNet(num_classes=5,width_mult=w, depth_mult=d).cuda()\n",
    "    p = sum(p.numel() for p in model.parameters())\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    data.append([w, d, score, p, t])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.5\n",
    "\n",
    "for w in widths:\n",
    "#     for d in depths:\n",
    "    print('width multiplier - %.3f depth multiplier - %.3f' % (w, d))\n",
    "    model = MobileNet(num_classes=5,width_mult=w, depth_mult=d).cuda()\n",
    "    p = sum(p.numel() for p in model.parameters())\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    data.append([w, d, score, p, t])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.3\n",
    "\n",
    "for w in widths:\n",
    "#     for d in depths:\n",
    "    print('width multiplier - %.3f depth multiplier - %.3f' % (w, d))\n",
    "    model = MobileNet(num_classes=5,width_mult=w, depth_mult=d).cuda()\n",
    "    p = sum(p.numel() for p in model.parameters())\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    data.append([w, d, score, p, t])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 0.2\n",
    "\n",
    "for w in widths:\n",
    "#     for d in depths:\n",
    "    print('width multiplier - %.3f depth multiplier - %.3f' % (w, d))\n",
    "    model = MobileNet(num_classes=5,width_mult=w, depth_mult=d).cuda()\n",
    "    p = sum(p.numel() for p in model.parameters())\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    data.append([w, d, score, p, t])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['width_x', 'depth_x', 'val_score', 'params', 'time_per_epoch']\n",
    "df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"chexpert_mobilenet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re = pd.read_csv('chexpert_mobilenet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
