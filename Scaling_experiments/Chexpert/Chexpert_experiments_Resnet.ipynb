{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(5)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../../prepare_data.py\n",
    "%run ../../architectures.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, valid_dataset = get_chexpert_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 256, 256]), torch.Size([32, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(num_classes=5).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11179077"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# lrs, losses = LR_range_finder(model, train_loader, \n",
    "#                               loss_fn=F.binary_cross_entropy_with_logits, \n",
    "#                               binary=False, lr_high=0.05)\n",
    "# plot_lr(lrs, losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "widths = [1.0, 0.75, 0.5, 0.25]\n",
    "depths = [[[[64, 2], [128, 2]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 2], [128, 2]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 1], [512, 1]]],\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width multiplier - 1.000 depth multiplier - 7.000\n",
      "train_loss 0.411 val_loss 0.417 val_auc_score 0.633\n",
      "----End of step 0:01:29.231922\n",
      "train_loss 0.397 val_loss 0.417 val_auc_score 0.658\n",
      "----End of step 0:01:29.793563\n",
      "train_loss 0.391 val_loss 0.404 val_auc_score 0.674\n",
      "----End of step 0:01:33.081681\n",
      "train_loss 0.385 val_loss 0.403 val_auc_score 0.687\n",
      "----End of step 0:01:34.369049\n",
      "train_loss 0.381 val_loss 0.398 val_auc_score 0.686\n",
      "----End of step 0:01:35.963838\n",
      "train_loss 0.379 val_loss 0.418 val_auc_score 0.693\n",
      "----End of step 0:01:36.583420\n",
      "train_loss 0.375 val_loss 0.388 val_auc_score 0.706\n",
      "----End of step 0:01:35.063999\n",
      "train_loss 0.372 val_loss 0.401 val_auc_score 0.702\n",
      "----End of step 0:01:34.811404\n",
      "train_loss 0.369 val_loss 0.390 val_auc_score 0.702\n",
      "----End of step 0:01:35.061466\n",
      "train_loss 0.365 val_loss 0.382 val_auc_score 0.716\n",
      "----End of step 0:01:35.066333\n",
      "train_loss 0.362 val_loss 0.387 val_auc_score 0.716\n",
      "----End of step 0:01:34.873348\n",
      "train_loss 0.359 val_loss 0.379 val_auc_score 0.723\n",
      "----End of step 0:01:34.738997\n",
      "train_loss 0.356 val_loss 0.380 val_auc_score 0.723\n",
      "----End of step 0:01:34.725028\n",
      "train_loss 0.354 val_loss 0.381 val_auc_score 0.723\n",
      "----End of step 0:01:34.535436\n",
      "train_loss 0.353 val_loss 0.380 val_auc_score 0.723\n",
      "----End of step 0:01:34.742227\n",
      "\n",
      "width multiplier - 1.000 depth multiplier - 6.000\n",
      "train_loss 0.410 val_loss 0.417 val_auc_score 0.646\n",
      "----End of step 0:01:30.991181\n",
      "train_loss 0.399 val_loss 0.419 val_auc_score 0.668\n",
      "----End of step 0:01:30.821206\n",
      "train_loss 0.391 val_loss 0.407 val_auc_score 0.681\n",
      "----End of step 0:01:31.106840\n",
      "train_loss 0.385 val_loss 0.403 val_auc_score 0.684\n",
      "----End of step 0:01:30.948621\n",
      "train_loss 0.382 val_loss 0.412 val_auc_score 0.694\n",
      "----End of step 0:01:31.139257\n",
      "train_loss 0.378 val_loss 0.393 val_auc_score 0.698\n",
      "----End of step 0:01:30.696894\n",
      "train_loss 0.375 val_loss 0.419 val_auc_score 0.687\n",
      "----End of step 0:01:31.580354\n",
      "train_loss 0.372 val_loss 0.395 val_auc_score 0.707\n",
      "----End of step 0:01:31.346453\n",
      "train_loss 0.368 val_loss 0.390 val_auc_score 0.709\n",
      "----End of step 0:01:31.338729\n",
      "train_loss 0.365 val_loss 0.385 val_auc_score 0.717\n",
      "----End of step 0:01:31.406825\n",
      "train_loss 0.362 val_loss 0.385 val_auc_score 0.719\n",
      "----End of step 0:01:31.408175\n",
      "train_loss 0.359 val_loss 0.382 val_auc_score 0.722\n",
      "----End of step 0:01:31.229864\n",
      "train_loss 0.357 val_loss 0.386 val_auc_score 0.721\n",
      "----End of step 0:01:30.798154\n",
      "train_loss 0.355 val_loss 0.382 val_auc_score 0.722\n",
      "----End of step 0:01:30.913602\n",
      "train_loss 0.354 val_loss 0.382 val_auc_score 0.723\n",
      "----End of step 0:01:31.118204\n",
      "\n",
      "width multiplier - 1.000 depth multiplier - 5.000\n",
      "train_loss 0.410 val_loss 0.417 val_auc_score 0.658\n",
      "----End of step 0:01:26.441944\n",
      "train_loss 0.398 val_loss 0.409 val_auc_score 0.665\n",
      "----End of step 0:01:26.268855\n",
      "train_loss 0.392 val_loss 0.405 val_auc_score 0.680\n",
      "----End of step 0:01:26.982792\n",
      "train_loss 0.385 val_loss 0.400 val_auc_score 0.685\n",
      "----End of step 0:01:27.915405\n",
      "train_loss 0.381 val_loss 0.398 val_auc_score 0.690\n",
      "----End of step 0:01:26.768190\n",
      "train_loss 0.379 val_loss 0.401 val_auc_score 0.702\n",
      "----End of step 0:01:26.371475\n",
      "train_loss 0.376 val_loss 0.397 val_auc_score 0.694\n",
      "----End of step 0:01:26.118912\n",
      "train_loss 0.372 val_loss 0.406 val_auc_score 0.694\n",
      "----End of step 0:01:25.859202\n",
      "train_loss 0.370 val_loss 0.386 val_auc_score 0.710\n",
      "----End of step 0:01:25.944004\n",
      "train_loss 0.366 val_loss 0.392 val_auc_score 0.716\n",
      "----End of step 0:01:25.931655\n",
      "train_loss 0.363 val_loss 0.397 val_auc_score 0.717\n",
      "----End of step 0:01:26.092227\n",
      "train_loss 0.360 val_loss 0.385 val_auc_score 0.718\n",
      "----End of step 0:01:26.252815\n",
      "train_loss 0.358 val_loss 0.381 val_auc_score 0.720\n",
      "----End of step 0:01:26.334157\n",
      "train_loss 0.355 val_loss 0.383 val_auc_score 0.721\n",
      "----End of step 0:01:26.315680\n",
      "train_loss 0.354 val_loss 0.383 val_auc_score 0.722\n",
      "----End of step 0:01:26.716200\n",
      "\n",
      "width multiplier - 1.000 depth multiplier - 6.000\n",
      "train_loss 0.409 val_loss 0.413 val_auc_score 0.662\n",
      "----End of step 0:01:30.729052\n",
      "train_loss 0.397 val_loss 0.416 val_auc_score 0.670\n",
      "----End of step 0:01:30.436495\n",
      "train_loss 0.391 val_loss 0.405 val_auc_score 0.676\n",
      "----End of step 0:01:30.070815\n",
      "train_loss 0.385 val_loss 0.394 val_auc_score 0.687\n",
      "----End of step 0:01:30.149702\n",
      "train_loss 0.381 val_loss 0.397 val_auc_score 0.686\n",
      "----End of step 0:01:29.892711\n",
      "train_loss 0.378 val_loss 0.392 val_auc_score 0.696\n",
      "----End of step 0:01:29.905952\n",
      "train_loss 0.375 val_loss 0.398 val_auc_score 0.694\n",
      "----End of step 0:01:29.920558\n",
      "train_loss 0.371 val_loss 0.389 val_auc_score 0.713\n",
      "----End of step 0:01:30.244090\n",
      "train_loss 0.369 val_loss 0.398 val_auc_score 0.699\n",
      "----End of step 0:01:29.632317\n",
      "train_loss 0.366 val_loss 0.381 val_auc_score 0.713\n",
      "----End of step 0:01:29.962217\n",
      "train_loss 0.363 val_loss 0.386 val_auc_score 0.717\n",
      "----End of step 0:01:29.966430\n",
      "train_loss 0.360 val_loss 0.378 val_auc_score 0.721\n",
      "----End of step 0:01:30.032562\n",
      "train_loss 0.357 val_loss 0.386 val_auc_score 0.720\n",
      "----End of step 0:01:30.075074\n",
      "train_loss 0.355 val_loss 0.381 val_auc_score 0.723\n",
      "----End of step 0:01:30.254563\n",
      "train_loss 0.353 val_loss 0.381 val_auc_score 0.723\n",
      "----End of step 0:01:30.398573\n",
      "\n",
      "width multiplier - 1.000 depth multiplier - 5.000\n",
      "train_loss 0.409 val_loss 0.416 val_auc_score 0.661\n",
      "----End of step 0:01:17.328079\n",
      "train_loss 0.398 val_loss 0.398 val_auc_score 0.675\n",
      "----End of step 0:01:18.573301\n",
      "train_loss 0.391 val_loss 0.416 val_auc_score 0.684\n",
      "----End of step 0:01:18.525774\n",
      "train_loss 0.386 val_loss 0.402 val_auc_score 0.691\n",
      "----End of step 0:01:18.797330\n",
      "train_loss 0.381 val_loss 0.396 val_auc_score 0.695\n",
      "----End of step 0:01:17.175658\n",
      "train_loss 0.378 val_loss 0.387 val_auc_score 0.702\n",
      "----End of step 0:01:18.542650\n",
      "train_loss 0.374 val_loss 0.394 val_auc_score 0.707\n",
      "----End of step 0:01:18.627590\n",
      "train_loss 0.372 val_loss 0.390 val_auc_score 0.707\n",
      "----End of step 0:01:17.511080\n",
      "train_loss 0.369 val_loss 0.381 val_auc_score 0.713\n",
      "----End of step 0:01:17.927080\n",
      "train_loss 0.366 val_loss 0.384 val_auc_score 0.716\n",
      "----End of step 0:01:18.025509\n",
      "train_loss 0.363 val_loss 0.391 val_auc_score 0.718\n",
      "----End of step 0:01:17.790973\n",
      "train_loss 0.359 val_loss 0.380 val_auc_score 0.722\n",
      "----End of step 0:01:17.691164\n",
      "train_loss 0.357 val_loss 0.385 val_auc_score 0.722\n",
      "----End of step 0:01:18.144718\n",
      "train_loss 0.355 val_loss 0.381 val_auc_score 0.723\n",
      "----End of step 0:01:17.972089\n",
      "train_loss 0.354 val_loss 0.381 val_auc_score 0.724\n",
      "----End of step 0:01:18.300063\n",
      "\n",
      "width multiplier - 1.000 depth multiplier - 4.000\n",
      "train_loss 0.413 val_loss 0.414 val_auc_score 0.649\n",
      "----End of step 0:01:13.975290\n",
      "train_loss 0.398 val_loss 0.407 val_auc_score 0.675\n",
      "----End of step 0:01:13.640624\n",
      "train_loss 0.393 val_loss 0.434 val_auc_score 0.662\n",
      "----End of step 0:01:13.843270\n",
      "train_loss 0.386 val_loss 0.408 val_auc_score 0.674\n",
      "----End of step 0:01:14.263292\n",
      "train_loss 0.382 val_loss 0.405 val_auc_score 0.691\n",
      "----End of step 0:01:14.151596\n",
      "train_loss 0.379 val_loss 0.403 val_auc_score 0.696\n",
      "----End of step 0:01:14.130732\n",
      "train_loss 0.376 val_loss 0.393 val_auc_score 0.703\n",
      "----End of step 0:01:13.948908\n",
      "train_loss 0.373 val_loss 0.405 val_auc_score 0.706\n",
      "----End of step 0:01:14.390748\n",
      "train_loss 0.369 val_loss 0.390 val_auc_score 0.706\n",
      "----End of step 0:01:14.133268\n",
      "train_loss 0.366 val_loss 0.380 val_auc_score 0.717\n",
      "----End of step 0:01:14.572062\n",
      "train_loss 0.363 val_loss 0.384 val_auc_score 0.712\n",
      "----End of step 0:01:13.684123\n",
      "train_loss 0.361 val_loss 0.382 val_auc_score 0.718\n",
      "----End of step 0:01:14.406773\n",
      "train_loss 0.358 val_loss 0.383 val_auc_score 0.722\n",
      "----End of step 0:01:14.512245\n",
      "train_loss 0.356 val_loss 0.379 val_auc_score 0.723\n",
      "----End of step 0:01:15.376563\n",
      "train_loss 0.355 val_loss 0.379 val_auc_score 0.722\n",
      "----End of step 0:01:15.005705\n",
      "\n",
      "width multiplier - 0.750 depth multiplier - 7.000\n",
      "train_loss 0.414 val_loss 0.424 val_auc_score 0.633\n",
      "----End of step 0:01:21.282704\n",
      "train_loss 0.398 val_loss 0.412 val_auc_score 0.651\n",
      "----End of step 0:01:20.446358\n",
      "train_loss 0.390 val_loss 0.403 val_auc_score 0.668\n",
      "----End of step 0:01:21.627619\n",
      "train_loss 0.384 val_loss 0.406 val_auc_score 0.683\n",
      "----End of step 0:01:21.500050\n",
      "train_loss 0.381 val_loss 0.400 val_auc_score 0.684\n",
      "----End of step 0:01:21.022840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.377 val_loss 0.403 val_auc_score 0.697\n",
      "----End of step 0:01:20.665688\n",
      "train_loss 0.374 val_loss 0.400 val_auc_score 0.703\n",
      "----End of step 0:01:20.601409\n",
      "train_loss 0.371 val_loss 0.385 val_auc_score 0.704\n",
      "----End of step 0:01:20.682445\n",
      "train_loss 0.368 val_loss 0.383 val_auc_score 0.707\n",
      "----End of step 0:01:20.489084\n",
      "train_loss 0.365 val_loss 0.385 val_auc_score 0.708\n",
      "----End of step 0:01:20.591338\n",
      "train_loss 0.362 val_loss 0.386 val_auc_score 0.706\n",
      "----End of step 0:01:20.438862\n",
      "train_loss 0.360 val_loss 0.379 val_auc_score 0.718\n",
      "----End of step 0:01:20.316658\n",
      "train_loss 0.357 val_loss 0.377 val_auc_score 0.719\n",
      "----End of step 0:01:19.943016\n",
      "train_loss 0.354 val_loss 0.378 val_auc_score 0.718\n",
      "----End of step 0:01:20.162583\n",
      "train_loss 0.354 val_loss 0.378 val_auc_score 0.719\n",
      "----End of step 0:01:20.496334\n",
      "\n",
      "width multiplier - 0.750 depth multiplier - 6.000\n",
      "train_loss 0.413 val_loss 0.430 val_auc_score 0.620\n",
      "----End of step 0:01:17.848270\n",
      "train_loss 0.400 val_loss 0.414 val_auc_score 0.658\n",
      "----End of step 0:01:18.561860\n",
      "train_loss 0.392 val_loss 0.409 val_auc_score 0.676\n",
      "----End of step 0:01:17.755941\n",
      "train_loss 0.386 val_loss 0.399 val_auc_score 0.680\n",
      "----End of step 0:01:17.732708\n",
      "train_loss 0.381 val_loss 0.398 val_auc_score 0.694\n",
      "----End of step 0:01:17.770014\n",
      "train_loss 0.378 val_loss 0.403 val_auc_score 0.689\n",
      "----End of step 0:01:17.502041\n",
      "train_loss 0.375 val_loss 0.387 val_auc_score 0.702\n",
      "----End of step 0:01:17.531357\n",
      "train_loss 0.372 val_loss 0.385 val_auc_score 0.703\n",
      "----End of step 0:01:17.505386\n",
      "train_loss 0.369 val_loss 0.383 val_auc_score 0.705\n",
      "----End of step 0:01:17.685240\n",
      "train_loss 0.366 val_loss 0.385 val_auc_score 0.705\n",
      "----End of step 0:01:17.837429\n",
      "train_loss 0.363 val_loss 0.381 val_auc_score 0.714\n",
      "----End of step 0:01:17.904234\n",
      "train_loss 0.360 val_loss 0.387 val_auc_score 0.713\n",
      "----End of step 0:01:18.031288\n",
      "train_loss 0.357 val_loss 0.381 val_auc_score 0.721\n",
      "----End of step 0:01:17.453478\n",
      "train_loss 0.356 val_loss 0.382 val_auc_score 0.719\n",
      "----End of step 0:01:17.611188\n",
      "train_loss 0.354 val_loss 0.381 val_auc_score 0.720\n",
      "----End of step 0:01:17.609080\n",
      "\n",
      "width multiplier - 0.750 depth multiplier - 5.000\n",
      "train_loss 0.415 val_loss 0.438 val_auc_score 0.609\n",
      "----End of step 0:01:13.731887\n",
      "train_loss 0.399 val_loss 0.412 val_auc_score 0.648\n",
      "----End of step 0:01:13.835812\n",
      "train_loss 0.391 val_loss 0.400 val_auc_score 0.669\n",
      "----End of step 0:01:14.564323\n",
      "train_loss 0.386 val_loss 0.406 val_auc_score 0.662\n",
      "----End of step 0:01:14.643982\n",
      "train_loss 0.381 val_loss 0.401 val_auc_score 0.679\n",
      "----End of step 0:01:14.425107\n",
      "train_loss 0.378 val_loss 0.398 val_auc_score 0.686\n",
      "----End of step 0:01:13.759399\n",
      "train_loss 0.374 val_loss 0.390 val_auc_score 0.693\n",
      "----End of step 0:01:13.406595\n",
      "train_loss 0.372 val_loss 0.390 val_auc_score 0.696\n",
      "----End of step 0:01:13.343918\n",
      "train_loss 0.369 val_loss 0.387 val_auc_score 0.703\n",
      "----End of step 0:01:13.271054\n",
      "train_loss 0.365 val_loss 0.385 val_auc_score 0.711\n",
      "----End of step 0:01:13.470069\n",
      "train_loss 0.363 val_loss 0.388 val_auc_score 0.707\n",
      "----End of step 0:01:13.247385\n",
      "train_loss 0.361 val_loss 0.385 val_auc_score 0.712\n",
      "----End of step 0:01:13.574232\n",
      "train_loss 0.357 val_loss 0.387 val_auc_score 0.713\n",
      "----End of step 0:01:13.267804\n",
      "train_loss 0.356 val_loss 0.386 val_auc_score 0.715\n",
      "----End of step 0:01:14.224252\n",
      "train_loss 0.355 val_loss 0.386 val_auc_score 0.715\n",
      "----End of step 0:01:14.781458\n",
      "\n",
      "width multiplier - 0.750 depth multiplier - 6.000\n",
      "train_loss 0.413 val_loss 0.418 val_auc_score 0.646\n",
      "----End of step 0:01:18.699036\n",
      "train_loss 0.397 val_loss 0.421 val_auc_score 0.663\n",
      "----End of step 0:01:17.654987\n",
      "train_loss 0.390 val_loss 0.405 val_auc_score 0.660\n",
      "----End of step 0:01:18.368580\n",
      "train_loss 0.384 val_loss 0.401 val_auc_score 0.676\n",
      "----End of step 0:01:17.612008\n",
      "train_loss 0.380 val_loss 0.401 val_auc_score 0.676\n",
      "----End of step 0:01:17.918379\n",
      "train_loss 0.378 val_loss 0.396 val_auc_score 0.687\n",
      "----End of step 0:01:19.246130\n",
      "train_loss 0.375 val_loss 0.388 val_auc_score 0.697\n",
      "----End of step 0:01:19.693227\n",
      "train_loss 0.371 val_loss 0.393 val_auc_score 0.691\n",
      "----End of step 0:01:19.157480\n",
      "train_loss 0.369 val_loss 0.398 val_auc_score 0.705\n",
      "----End of step 0:01:20.208107\n",
      "train_loss 0.365 val_loss 0.384 val_auc_score 0.712\n",
      "----End of step 0:01:18.840172\n",
      "train_loss 0.363 val_loss 0.387 val_auc_score 0.712\n",
      "----End of step 0:01:19.384885\n",
      "train_loss 0.360 val_loss 0.387 val_auc_score 0.716\n",
      "----End of step 0:01:19.291681\n",
      "train_loss 0.358 val_loss 0.383 val_auc_score 0.719\n",
      "----End of step 0:01:19.368101\n",
      "train_loss 0.355 val_loss 0.385 val_auc_score 0.719\n",
      "----End of step 0:01:20.458072\n",
      "train_loss 0.355 val_loss 0.386 val_auc_score 0.719\n",
      "----End of step 0:01:19.884928\n",
      "\n",
      "width multiplier - 0.750 depth multiplier - 5.000\n",
      "train_loss 0.413 val_loss 0.420 val_auc_score 0.626\n",
      "----End of step 0:01:15.307896\n",
      "train_loss 0.400 val_loss 0.437 val_auc_score 0.623\n",
      "----End of step 0:01:15.995710\n",
      "train_loss 0.392 val_loss 0.403 val_auc_score 0.676\n",
      "----End of step 0:01:18.144051\n",
      "train_loss 0.385 val_loss 0.396 val_auc_score 0.679\n",
      "----End of step 0:01:15.429454\n",
      "train_loss 0.381 val_loss 0.401 val_auc_score 0.669\n",
      "----End of step 0:01:13.939716\n",
      "train_loss 0.378 val_loss 0.399 val_auc_score 0.685\n",
      "----End of step 0:01:14.043342\n",
      "train_loss 0.375 val_loss 0.395 val_auc_score 0.690\n",
      "----End of step 0:01:12.910047\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for w in widths:\n",
    "    for d in depths:\n",
    "        d_s = sum(j[1] for i in d for j in i)\n",
    "        print('width multiplier - %.3f depth multiplier - %.3f' % (w, d_s))\n",
    "        model = resnet18(num_classes=5, width_mult=w, \n",
    "                         inverted_residual_setting1=d[0], \n",
    "                         inverted_residual_setting2=d[1]).cuda()\n",
    "        \n",
    "        p = sum(p.numel() for p in model.parameters())\n",
    "        optimizer = create_optimizer(model, 0.001)\n",
    "        score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "        \n",
    "        p = \"/home/rimmanni/Medical_Images/Scaling_experiments/Chexpert/Resnet_\" + str(w) + '_' + str(depths.index(d))\n",
    "        save_model(model, p)\n",
    "        data.append([w, d_s, score, p, t])\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['width_x', 'depth_x', 'val_score', 'params', 'time_per_epoch']\n",
    "df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"chexpert_resnet_13.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re = pd.read_csv('chexpert_resnet_13.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_re.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
