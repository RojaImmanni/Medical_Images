{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../architectures.py\n",
    "%run ../prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, valid_dataset = mura_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 250, 200]), torch.Size([32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [[[[64, 2], [128, 2]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 2], [128, 2]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 1], [512, 1]]],\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.553 val_loss 0.572 val_auc_score 0.815\n",
      "----End of step 0:00:42.889112\n",
      "train_loss 0.524 val_loss 0.522 val_auc_score 0.829\n",
      "----End of step 0:00:45.450120\n",
      "train_loss 0.515 val_loss 0.559 val_auc_score 0.801\n",
      "----End of step 0:00:43.449776\n",
      "train_loss 0.505 val_loss 0.547 val_auc_score 0.835\n",
      "----End of step 0:00:44.937229\n",
      "train_loss 0.493 val_loss 0.541 val_auc_score 0.836\n",
      "----End of step 0:00:44.042894\n",
      "train_loss 0.487 val_loss 0.524 val_auc_score 0.835\n",
      "----End of step 0:00:44.216277\n",
      "train_loss 0.477 val_loss 0.529 val_auc_score 0.837\n",
      "----End of step 0:00:46.091962\n",
      "train_loss 0.464 val_loss 0.513 val_auc_score 0.855\n",
      "----End of step 0:00:46.198767\n",
      "train_loss 0.453 val_loss 0.475 val_auc_score 0.864\n",
      "----End of step 0:00:47.293043\n",
      "train_loss 0.441 val_loss 0.478 val_auc_score 0.869\n",
      "----End of step 0:00:45.298836\n",
      "train_loss 0.426 val_loss 0.468 val_auc_score 0.874\n",
      "----End of step 0:00:46.574712\n",
      "train_loss 0.411 val_loss 0.491 val_auc_score 0.875\n",
      "----End of step 0:00:47.190847\n",
      "train_loss 0.399 val_loss 0.468 val_auc_score 0.876\n",
      "----End of step 0:00:45.814106\n",
      "train_loss 0.389 val_loss 0.466 val_auc_score 0.877\n",
      "----End of step 0:00:47.176104\n",
      "train_loss 0.382 val_loss 0.462 val_auc_score 0.878\n",
      "----End of step 0:00:47.201919\n",
      "train_loss 0.556 val_loss 0.550 val_auc_score 0.807\n",
      "----End of step 0:00:45.993918\n",
      "train_loss 0.520 val_loss 0.537 val_auc_score 0.826\n",
      "----End of step 0:00:46.621481\n",
      "train_loss 0.515 val_loss 0.533 val_auc_score 0.825\n",
      "----End of step 0:00:46.532305\n",
      "train_loss 0.506 val_loss 0.527 val_auc_score 0.825\n",
      "----End of step 0:00:46.082588\n",
      "train_loss 0.494 val_loss 0.579 val_auc_score 0.845\n",
      "----End of step 0:00:46.738592\n",
      "train_loss 0.487 val_loss 0.540 val_auc_score 0.835\n",
      "----End of step 0:00:46.299588\n",
      "train_loss 0.473 val_loss 0.519 val_auc_score 0.836\n",
      "----End of step 0:00:46.661925\n",
      "train_loss 0.463 val_loss 0.494 val_auc_score 0.848\n",
      "----End of step 0:00:47.082511\n",
      "train_loss 0.454 val_loss 0.480 val_auc_score 0.863\n",
      "----End of step 0:00:46.373694\n",
      "train_loss 0.439 val_loss 0.484 val_auc_score 0.870\n",
      "----End of step 0:00:46.162596\n",
      "train_loss 0.427 val_loss 0.472 val_auc_score 0.866\n",
      "----End of step 0:00:45.570423\n",
      "train_loss 0.413 val_loss 0.477 val_auc_score 0.874\n",
      "----End of step 0:00:46.918348\n",
      "train_loss 0.398 val_loss 0.472 val_auc_score 0.876\n",
      "----End of step 0:00:46.712382\n",
      "train_loss 0.390 val_loss 0.473 val_auc_score 0.875\n",
      "----End of step 0:00:46.071200\n",
      "train_loss 0.383 val_loss 0.473 val_auc_score 0.876\n",
      "----End of step 0:00:46.109273\n",
      "train_loss 0.553 val_loss 0.643 val_auc_score 0.807\n",
      "----End of step 0:00:46.994421\n",
      "train_loss 0.520 val_loss 0.532 val_auc_score 0.828\n",
      "----End of step 0:00:46.406421\n",
      "train_loss 0.514 val_loss 0.648 val_auc_score 0.833\n",
      "----End of step 0:00:45.501132\n",
      "train_loss 0.506 val_loss 0.505 val_auc_score 0.844\n",
      "----End of step 0:00:45.292944\n",
      "train_loss 0.494 val_loss 0.507 val_auc_score 0.845\n",
      "----End of step 0:00:46.436975\n",
      "train_loss 0.487 val_loss 0.590 val_auc_score 0.808\n",
      "----End of step 0:00:47.390053\n",
      "train_loss 0.475 val_loss 0.488 val_auc_score 0.858\n",
      "----End of step 0:00:45.829334\n",
      "train_loss 0.465 val_loss 0.522 val_auc_score 0.835\n",
      "----End of step 0:00:46.369496\n",
      "train_loss 0.453 val_loss 0.535 val_auc_score 0.865\n",
      "----End of step 0:00:46.001112\n",
      "train_loss 0.440 val_loss 0.507 val_auc_score 0.856\n",
      "----End of step 0:00:47.080974\n",
      "train_loss 0.426 val_loss 0.475 val_auc_score 0.870\n",
      "----End of step 0:00:46.397393\n",
      "train_loss 0.413 val_loss 0.481 val_auc_score 0.875\n",
      "----End of step 0:00:46.308517\n",
      "train_loss 0.399 val_loss 0.459 val_auc_score 0.878\n",
      "----End of step 0:00:47.017722\n",
      "train_loss 0.390 val_loss 0.460 val_auc_score 0.880\n",
      "----End of step 0:00:46.704022\n",
      "train_loss 0.386 val_loss 0.463 val_auc_score 0.879\n",
      "----End of step 0:00:46.245223\n",
      "train_loss 0.556 val_loss 0.562 val_auc_score 0.809\n",
      "----End of step 0:00:47.017728\n",
      "train_loss 0.523 val_loss 0.592 val_auc_score 0.802\n",
      "----End of step 0:00:47.625651\n",
      "train_loss 0.517 val_loss 0.523 val_auc_score 0.836\n",
      "----End of step 0:00:47.572709\n",
      "train_loss 0.506 val_loss 0.553 val_auc_score 0.835\n",
      "----End of step 0:00:46.792826\n",
      "train_loss 0.497 val_loss 0.585 val_auc_score 0.810\n",
      "----End of step 0:00:47.124652\n",
      "train_loss 0.487 val_loss 0.547 val_auc_score 0.845\n",
      "----End of step 0:00:46.627977\n",
      "train_loss 0.477 val_loss 0.591 val_auc_score 0.853\n",
      "----End of step 0:00:46.580476\n",
      "train_loss 0.465 val_loss 0.492 val_auc_score 0.858\n",
      "----End of step 0:00:45.401572\n",
      "train_loss 0.454 val_loss 0.518 val_auc_score 0.854\n",
      "----End of step 0:00:45.911190\n",
      "train_loss 0.442 val_loss 0.482 val_auc_score 0.866\n",
      "----End of step 0:00:46.145124\n",
      "train_loss 0.427 val_loss 0.468 val_auc_score 0.874\n",
      "----End of step 0:00:46.592778\n",
      "train_loss 0.412 val_loss 0.481 val_auc_score 0.865\n",
      "----End of step 0:00:46.777050\n",
      "train_loss 0.402 val_loss 0.469 val_auc_score 0.877\n",
      "----End of step 0:00:46.742832\n",
      "train_loss 0.391 val_loss 0.469 val_auc_score 0.876\n",
      "----End of step 0:00:46.428802\n",
      "train_loss 0.387 val_loss 0.472 val_auc_score 0.875\n",
      "----End of step 0:00:46.439725\n",
      "train_loss 0.559 val_loss 0.635 val_auc_score 0.828\n",
      "----End of step 0:00:46.791989\n",
      "train_loss 0.522 val_loss 0.586 val_auc_score 0.804\n",
      "----End of step 0:00:46.087098\n",
      "train_loss 0.513 val_loss 0.565 val_auc_score 0.817\n",
      "----End of step 0:00:46.399926\n",
      "train_loss 0.505 val_loss 0.609 val_auc_score 0.819\n",
      "----End of step 0:00:45.446539\n",
      "train_loss 0.495 val_loss 0.534 val_auc_score 0.823\n",
      "----End of step 0:00:46.045875\n",
      "train_loss 0.487 val_loss 0.545 val_auc_score 0.843\n",
      "----End of step 0:00:45.638224\n",
      "train_loss 0.474 val_loss 0.518 val_auc_score 0.848\n",
      "----End of step 0:00:45.866431\n",
      "train_loss 0.465 val_loss 0.546 val_auc_score 0.859\n",
      "----End of step 0:00:45.708186\n",
      "train_loss 0.453 val_loss 0.477 val_auc_score 0.860\n",
      "----End of step 0:00:46.924432\n",
      "train_loss 0.440 val_loss 0.531 val_auc_score 0.864\n",
      "----End of step 0:00:47.303692\n",
      "train_loss 0.426 val_loss 0.469 val_auc_score 0.866\n",
      "----End of step 0:00:48.407912\n",
      "train_loss 0.411 val_loss 0.484 val_auc_score 0.870\n",
      "----End of step 0:00:45.632512\n",
      "train_loss 0.400 val_loss 0.473 val_auc_score 0.872\n",
      "----End of step 0:00:44.881499\n",
      "train_loss 0.390 val_loss 0.475 val_auc_score 0.873\n",
      "----End of step 0:00:45.548290\n",
      "train_loss 0.383 val_loss 0.472 val_auc_score 0.874\n",
      "----End of step 0:00:45.846714\n",
      "train_loss 0.555 val_loss 0.539 val_auc_score 0.816\n",
      "----End of step 0:00:45.142834\n",
      "train_loss 0.520 val_loss 0.523 val_auc_score 0.836\n",
      "----End of step 0:00:45.290951\n",
      "train_loss 0.515 val_loss 0.695 val_auc_score 0.834\n",
      "----End of step 0:00:45.174789\n",
      "train_loss 0.505 val_loss 0.515 val_auc_score 0.835\n",
      "----End of step 0:00:45.320757\n",
      "train_loss 0.497 val_loss 0.567 val_auc_score 0.830\n",
      "----End of step 0:00:45.433618\n",
      "train_loss 0.486 val_loss 0.563 val_auc_score 0.843\n",
      "----End of step 0:00:45.277612\n",
      "train_loss 0.475 val_loss 0.525 val_auc_score 0.859\n",
      "----End of step 0:00:45.648282\n",
      "train_loss 0.463 val_loss 0.496 val_auc_score 0.856\n",
      "----End of step 0:00:46.606870\n",
      "train_loss 0.452 val_loss 0.486 val_auc_score 0.866\n",
      "----End of step 0:00:46.114064\n",
      "train_loss 0.441 val_loss 0.512 val_auc_score 0.876\n",
      "----End of step 0:00:45.031880\n",
      "train_loss 0.424 val_loss 0.469 val_auc_score 0.871\n",
      "----End of step 0:00:46.584041\n",
      "train_loss 0.409 val_loss 0.479 val_auc_score 0.871\n",
      "----End of step 0:00:47.228802\n",
      "train_loss 0.398 val_loss 0.469 val_auc_score 0.877\n",
      "----End of step 0:00:47.725799\n",
      "train_loss 0.389 val_loss 0.467 val_auc_score 0.878\n",
      "----End of step 0:00:47.809099\n",
      "train_loss 0.384 val_loss 0.471 val_auc_score 0.878\n",
      "----End of step 0:00:48.338744\n",
      "train_loss 0.555 val_loss 0.572 val_auc_score 0.807\n",
      "----End of step 0:00:46.051184\n",
      "train_loss 0.524 val_loss 0.548 val_auc_score 0.816\n",
      "----End of step 0:00:47.353776\n",
      "train_loss 0.517 val_loss 0.579 val_auc_score 0.842\n",
      "----End of step 0:00:46.863415\n",
      "train_loss 0.509 val_loss 0.518 val_auc_score 0.825\n",
      "----End of step 0:00:46.289266\n",
      "train_loss 0.496 val_loss 0.515 val_auc_score 0.833\n",
      "----End of step 0:00:48.952571\n",
      "train_loss 0.485 val_loss 0.520 val_auc_score 0.840\n",
      "----End of step 0:00:46.951937\n",
      "train_loss 0.479 val_loss 0.571 val_auc_score 0.847\n",
      "----End of step 0:00:46.635874\n",
      "train_loss 0.466 val_loss 0.499 val_auc_score 0.858\n",
      "----End of step 0:00:46.281484\n",
      "train_loss 0.453 val_loss 0.483 val_auc_score 0.858\n",
      "----End of step 0:00:46.815572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.441 val_loss 0.515 val_auc_score 0.859\n",
      "----End of step 0:00:47.465408\n",
      "train_loss 0.430 val_loss 0.468 val_auc_score 0.870\n",
      "----End of step 0:00:47.928095\n",
      "train_loss 0.412 val_loss 0.475 val_auc_score 0.875\n",
      "----End of step 0:00:46.153123\n",
      "train_loss 0.402 val_loss 0.472 val_auc_score 0.874\n",
      "----End of step 0:00:47.847253\n",
      "train_loss 0.392 val_loss 0.460 val_auc_score 0.879\n",
      "----End of step 0:00:47.544057\n",
      "train_loss 0.386 val_loss 0.462 val_auc_score 0.880\n",
      "----End of step 0:00:48.297756\n",
      "train_loss 0.559 val_loss 0.606 val_auc_score 0.789\n",
      "----End of step 0:00:46.434468\n",
      "train_loss 0.524 val_loss 0.611 val_auc_score 0.787\n",
      "----End of step 0:00:47.419631\n",
      "train_loss 0.514 val_loss 0.531 val_auc_score 0.832\n",
      "----End of step 0:00:47.608640\n",
      "train_loss 0.505 val_loss 0.539 val_auc_score 0.825\n",
      "----End of step 0:00:46.329516\n",
      "train_loss 0.493 val_loss 0.570 val_auc_score 0.815\n",
      "----End of step 0:00:46.742202\n",
      "train_loss 0.485 val_loss 0.498 val_auc_score 0.850\n",
      "----End of step 0:00:47.466159\n",
      "train_loss 0.473 val_loss 0.524 val_auc_score 0.857\n",
      "----End of step 0:00:46.101157\n",
      "train_loss 0.463 val_loss 0.502 val_auc_score 0.856\n",
      "----End of step 0:00:46.522184\n",
      "train_loss 0.450 val_loss 0.497 val_auc_score 0.868\n",
      "----End of step 0:00:46.740995\n",
      "train_loss 0.439 val_loss 0.514 val_auc_score 0.871\n",
      "----End of step 0:00:45.987164\n",
      "train_loss 0.425 val_loss 0.466 val_auc_score 0.871\n",
      "----End of step 0:00:47.276938\n",
      "train_loss 0.411 val_loss 0.466 val_auc_score 0.875\n",
      "----End of step 0:00:46.076763\n",
      "train_loss 0.399 val_loss 0.466 val_auc_score 0.879\n",
      "----End of step 0:00:47.425506\n",
      "train_loss 0.390 val_loss 0.464 val_auc_score 0.878\n",
      "----End of step 0:00:47.847083\n",
      "train_loss 0.385 val_loss 0.465 val_auc_score 0.878\n",
      "----End of step 0:00:50.272689\n",
      "train_loss 0.556 val_loss 0.559 val_auc_score 0.817\n",
      "----End of step 0:00:46.932135\n",
      "train_loss 0.522 val_loss 0.544 val_auc_score 0.823\n",
      "----End of step 0:00:47.687525\n",
      "train_loss 0.515 val_loss 0.560 val_auc_score 0.824\n",
      "----End of step 0:00:48.527713\n",
      "train_loss 0.504 val_loss 0.558 val_auc_score 0.822\n",
      "----End of step 0:00:46.150447\n",
      "train_loss 0.496 val_loss 0.544 val_auc_score 0.835\n",
      "----End of step 0:00:46.705813\n",
      "train_loss 0.486 val_loss 0.507 val_auc_score 0.852\n",
      "----End of step 0:00:46.659714\n",
      "train_loss 0.477 val_loss 0.521 val_auc_score 0.846\n",
      "----End of step 0:00:45.479795\n",
      "train_loss 0.467 val_loss 0.480 val_auc_score 0.857\n",
      "----End of step 0:00:48.259698\n",
      "train_loss 0.452 val_loss 0.478 val_auc_score 0.873\n",
      "----End of step 0:00:45.968564\n",
      "train_loss 0.440 val_loss 0.489 val_auc_score 0.868\n",
      "----End of step 0:00:49.978079\n",
      "train_loss 0.427 val_loss 0.469 val_auc_score 0.873\n",
      "----End of step 0:00:45.923337\n",
      "train_loss 0.412 val_loss 0.475 val_auc_score 0.878\n",
      "----End of step 0:00:46.713275\n",
      "train_loss 0.399 val_loss 0.465 val_auc_score 0.879\n",
      "----End of step 0:00:49.295181\n",
      "train_loss 0.390 val_loss 0.467 val_auc_score 0.877\n",
      "----End of step 0:00:46.055068\n",
      "train_loss 0.385 val_loss 0.466 val_auc_score 0.874\n",
      "----End of step 0:00:48.097226\n",
      "train_loss 0.553 val_loss 0.637 val_auc_score 0.810\n",
      "----End of step 0:00:45.357346\n",
      "train_loss 0.521 val_loss 0.537 val_auc_score 0.824\n",
      "----End of step 0:00:46.930991\n",
      "train_loss 0.515 val_loss 0.504 val_auc_score 0.851\n",
      "----End of step 0:00:46.783451\n",
      "train_loss 0.505 val_loss 0.513 val_auc_score 0.833\n",
      "----End of step 0:00:48.823346\n",
      "train_loss 0.496 val_loss 0.628 val_auc_score 0.835\n",
      "----End of step 0:00:45.464605\n",
      "train_loss 0.485 val_loss 0.513 val_auc_score 0.847\n",
      "----End of step 0:00:45.267425\n",
      "train_loss 0.477 val_loss 0.541 val_auc_score 0.829\n",
      "----End of step 0:00:47.189290\n",
      "train_loss 0.468 val_loss 0.508 val_auc_score 0.864\n",
      "----End of step 0:00:46.760536\n",
      "train_loss 0.453 val_loss 0.467 val_auc_score 0.876\n",
      "----End of step 0:00:46.361591\n",
      "train_loss 0.440 val_loss 0.463 val_auc_score 0.870\n",
      "----End of step 0:00:46.436795\n",
      "train_loss 0.426 val_loss 0.465 val_auc_score 0.872\n",
      "----End of step 0:00:46.094460\n",
      "train_loss 0.413 val_loss 0.480 val_auc_score 0.873\n",
      "----End of step 0:00:47.151609\n",
      "train_loss 0.399 val_loss 0.464 val_auc_score 0.876\n",
      "----End of step 0:00:46.035539\n",
      "train_loss 0.391 val_loss 0.469 val_auc_score 0.878\n",
      "----End of step 0:00:47.001316\n",
      "train_loss 0.384 val_loss 0.470 val_auc_score 0.878\n",
      "----End of step 0:00:46.561068\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(5):\n",
    "    model = resnet18(block=depthwise_block, num_classes=1000).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/model_320_iter20_770.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                               loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                               dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_full'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.25_full_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.603 val_loss 0.579 val_auc_score 0.792\n",
      "----End of step 0:00:47.077245\n",
      "train_loss 0.560 val_loss 0.792 val_auc_score 0.744\n",
      "----End of step 0:00:50.611362\n",
      "train_loss 0.548 val_loss 0.666 val_auc_score 0.811\n",
      "----End of step 0:00:50.156985\n",
      "train_loss 0.531 val_loss 0.546 val_auc_score 0.827\n",
      "----End of step 0:00:47.140513\n",
      "train_loss 0.524 val_loss 0.525 val_auc_score 0.832\n",
      "----End of step 0:00:47.953053\n",
      "train_loss 0.514 val_loss 0.522 val_auc_score 0.843\n",
      "----End of step 0:00:46.729966\n",
      "train_loss 0.504 val_loss 0.528 val_auc_score 0.832\n",
      "----End of step 0:00:48.748392\n",
      "train_loss 0.495 val_loss 0.537 val_auc_score 0.839\n",
      "----End of step 0:00:48.352727\n",
      "train_loss 0.487 val_loss 0.617 val_auc_score 0.841\n",
      "----End of step 0:00:48.244629\n",
      "train_loss 0.476 val_loss 0.529 val_auc_score 0.856\n",
      "----End of step 0:00:48.107387\n",
      "train_loss 0.464 val_loss 0.506 val_auc_score 0.845\n",
      "----End of step 0:00:53.054386\n",
      "train_loss 0.457 val_loss 0.499 val_auc_score 0.852\n",
      "----End of step 0:00:48.652220\n",
      "train_loss 0.451 val_loss 0.500 val_auc_score 0.857\n",
      "----End of step 0:00:49.187370\n",
      "train_loss 0.445 val_loss 0.492 val_auc_score 0.857\n",
      "----End of step 0:00:48.391073\n",
      "train_loss 0.443 val_loss 0.498 val_auc_score 0.855\n",
      "----End of step 0:00:50.438034\n",
      "train_loss 0.602 val_loss 0.676 val_auc_score 0.811\n",
      "----End of step 0:00:50.995859\n",
      "train_loss 0.560 val_loss 0.726 val_auc_score 0.774\n",
      "----End of step 0:00:47.098661\n",
      "train_loss 0.544 val_loss 0.548 val_auc_score 0.829\n",
      "----End of step 0:00:50.043220\n",
      "train_loss 0.534 val_loss 0.586 val_auc_score 0.801\n",
      "----End of step 0:00:48.303632\n",
      "train_loss 0.525 val_loss 0.563 val_auc_score 0.807\n",
      "----End of step 0:00:47.325015\n",
      "train_loss 0.514 val_loss 0.559 val_auc_score 0.820\n",
      "----End of step 0:00:47.425655\n",
      "train_loss 0.506 val_loss 0.516 val_auc_score 0.853\n",
      "----End of step 0:00:50.195948\n",
      "train_loss 0.495 val_loss 0.511 val_auc_score 0.847\n",
      "----End of step 0:00:50.523556\n",
      "train_loss 0.486 val_loss 0.511 val_auc_score 0.848\n",
      "----End of step 0:00:47.601507\n",
      "train_loss 0.478 val_loss 0.515 val_auc_score 0.858\n",
      "----End of step 0:00:48.928582\n",
      "train_loss 0.469 val_loss 0.496 val_auc_score 0.858\n",
      "----End of step 0:00:47.672609\n",
      "train_loss 0.459 val_loss 0.488 val_auc_score 0.863\n",
      "----End of step 0:00:47.648122\n",
      "train_loss 0.451 val_loss 0.489 val_auc_score 0.865\n",
      "----End of step 0:00:48.460276\n",
      "train_loss 0.447 val_loss 0.488 val_auc_score 0.866\n",
      "----End of step 0:00:47.367486\n",
      "train_loss 0.444 val_loss 0.492 val_auc_score 0.867\n",
      "----End of step 0:00:49.197679\n",
      "train_loss 0.606 val_loss 0.597 val_auc_score 0.780\n",
      "----End of step 0:00:48.367175\n",
      "train_loss 0.561 val_loss 0.593 val_auc_score 0.796\n",
      "----End of step 0:00:47.223173\n",
      "train_loss 0.547 val_loss 0.559 val_auc_score 0.815\n",
      "----End of step 0:00:48.109175\n",
      "train_loss 0.535 val_loss 0.545 val_auc_score 0.823\n",
      "----End of step 0:00:49.355950\n",
      "train_loss 0.526 val_loss 0.598 val_auc_score 0.828\n",
      "----End of step 0:00:49.126885\n",
      "train_loss 0.514 val_loss 0.648 val_auc_score 0.823\n",
      "----End of step 0:00:49.107311\n",
      "train_loss 0.505 val_loss 0.529 val_auc_score 0.834\n",
      "----End of step 0:00:48.882307\n",
      "train_loss 0.498 val_loss 0.544 val_auc_score 0.825\n",
      "----End of step 0:00:46.816984\n",
      "train_loss 0.487 val_loss 0.521 val_auc_score 0.854\n",
      "----End of step 0:00:46.750632\n",
      "train_loss 0.476 val_loss 0.498 val_auc_score 0.856\n",
      "----End of step 0:00:48.358981\n",
      "train_loss 0.465 val_loss 0.514 val_auc_score 0.841\n",
      "----End of step 0:00:48.288272\n",
      "train_loss 0.456 val_loss 0.510 val_auc_score 0.853\n",
      "----End of step 0:00:48.391319\n",
      "train_loss 0.450 val_loss 0.509 val_auc_score 0.857\n",
      "----End of step 0:00:46.873801\n",
      "train_loss 0.445 val_loss 0.498 val_auc_score 0.858\n",
      "----End of step 0:00:48.565814\n",
      "train_loss 0.441 val_loss 0.500 val_auc_score 0.858\n",
      "----End of step 0:00:47.489020\n",
      "train_loss 0.602 val_loss 0.592 val_auc_score 0.798\n",
      "----End of step 0:00:47.888222\n",
      "train_loss 0.558 val_loss 0.618 val_auc_score 0.798\n",
      "----End of step 0:00:46.911591\n",
      "train_loss 0.545 val_loss 0.644 val_auc_score 0.796\n",
      "----End of step 0:00:47.500267\n",
      "train_loss 0.533 val_loss 0.600 val_auc_score 0.809\n",
      "----End of step 0:00:47.154767\n",
      "train_loss 0.522 val_loss 0.558 val_auc_score 0.829\n",
      "----End of step 0:00:48.899529\n",
      "train_loss 0.512 val_loss 0.523 val_auc_score 0.850\n",
      "----End of step 0:00:47.149974\n",
      "train_loss 0.506 val_loss 0.625 val_auc_score 0.802\n",
      "----End of step 0:00:48.098539\n",
      "train_loss 0.493 val_loss 0.529 val_auc_score 0.827\n",
      "----End of step 0:00:47.043508\n",
      "train_loss 0.487 val_loss 0.516 val_auc_score 0.844\n",
      "----End of step 0:00:46.957366\n",
      "train_loss 0.473 val_loss 0.534 val_auc_score 0.831\n",
      "----End of step 0:00:47.615047\n",
      "train_loss 0.467 val_loss 0.520 val_auc_score 0.856\n",
      "----End of step 0:00:47.412443\n",
      "train_loss 0.459 val_loss 0.508 val_auc_score 0.858\n",
      "----End of step 0:00:46.941005\n",
      "train_loss 0.449 val_loss 0.513 val_auc_score 0.860\n",
      "----End of step 0:00:48.620571\n",
      "train_loss 0.439 val_loss 0.503 val_auc_score 0.861\n",
      "----End of step 0:00:50.768540\n",
      "train_loss 0.439 val_loss 0.509 val_auc_score 0.861\n",
      "----End of step 0:00:46.743237\n",
      "train_loss 0.603 val_loss 0.677 val_auc_score 0.752\n",
      "----End of step 0:00:47.842413\n",
      "train_loss 0.564 val_loss 0.849 val_auc_score 0.775\n",
      "----End of step 0:00:47.586322\n",
      "train_loss 0.547 val_loss 0.569 val_auc_score 0.807\n",
      "----End of step 0:00:47.469468\n",
      "train_loss 0.533 val_loss 0.580 val_auc_score 0.819\n",
      "----End of step 0:00:46.814621\n",
      "train_loss 0.524 val_loss 0.548 val_auc_score 0.841\n",
      "----End of step 0:00:48.573228\n",
      "train_loss 0.512 val_loss 0.585 val_auc_score 0.818\n",
      "----End of step 0:00:46.413868\n",
      "train_loss 0.505 val_loss 0.596 val_auc_score 0.821\n",
      "----End of step 0:00:44.690638\n",
      "train_loss 0.496 val_loss 0.509 val_auc_score 0.849\n",
      "----End of step 0:00:45.145328\n",
      "train_loss 0.486 val_loss 0.528 val_auc_score 0.846\n",
      "----End of step 0:00:45.870481\n",
      "train_loss 0.478 val_loss 0.518 val_auc_score 0.853\n",
      "----End of step 0:00:44.524624\n",
      "train_loss 0.469 val_loss 0.537 val_auc_score 0.849\n",
      "----End of step 0:00:45.862071\n",
      "train_loss 0.458 val_loss 0.509 val_auc_score 0.861\n",
      "----End of step 0:00:46.065974\n",
      "train_loss 0.451 val_loss 0.490 val_auc_score 0.859\n",
      "----End of step 0:00:46.864857\n",
      "train_loss 0.443 val_loss 0.496 val_auc_score 0.862\n",
      "----End of step 0:00:46.429981\n",
      "train_loss 0.441 val_loss 0.500 val_auc_score 0.863\n",
      "----End of step 0:00:46.491521\n",
      "train_loss 0.605 val_loss 0.597 val_auc_score 0.764\n",
      "----End of step 0:00:45.839185\n",
      "train_loss 0.563 val_loss 0.583 val_auc_score 0.786\n",
      "----End of step 0:00:45.974623\n",
      "train_loss 0.549 val_loss 0.632 val_auc_score 0.801\n",
      "----End of step 0:00:47.008172\n",
      "train_loss 0.535 val_loss 0.591 val_auc_score 0.840\n",
      "----End of step 0:00:46.547789\n",
      "train_loss 0.524 val_loss 0.525 val_auc_score 0.840\n",
      "----End of step 0:00:46.869354\n",
      "train_loss 0.515 val_loss 0.543 val_auc_score 0.828\n",
      "----End of step 0:00:46.939473\n",
      "train_loss 0.505 val_loss 0.553 val_auc_score 0.843\n",
      "----End of step 0:00:48.026059\n",
      "train_loss 0.499 val_loss 0.544 val_auc_score 0.844\n",
      "----End of step 0:00:46.821194\n",
      "train_loss 0.485 val_loss 0.510 val_auc_score 0.852\n",
      "----End of step 0:00:47.937490\n",
      "train_loss 0.477 val_loss 0.519 val_auc_score 0.856\n",
      "----End of step 0:00:47.345754\n",
      "train_loss 0.467 val_loss 0.495 val_auc_score 0.864\n",
      "----End of step 0:00:47.352255\n",
      "train_loss 0.458 val_loss 0.494 val_auc_score 0.864\n",
      "----End of step 0:00:47.430987\n",
      "train_loss 0.451 val_loss 0.506 val_auc_score 0.860\n",
      "----End of step 0:00:46.393027\n",
      "train_loss 0.445 val_loss 0.492 val_auc_score 0.869\n",
      "----End of step 0:00:47.160216\n",
      "train_loss 0.440 val_loss 0.490 val_auc_score 0.869\n",
      "----End of step 0:00:47.298874\n",
      "train_loss 0.601 val_loss 0.597 val_auc_score 0.788\n",
      "----End of step 0:00:48.470823\n",
      "train_loss 0.558 val_loss 0.567 val_auc_score 0.795\n",
      "----End of step 0:00:50.991802\n",
      "train_loss 0.544 val_loss 0.555 val_auc_score 0.810\n",
      "----End of step 0:00:47.130938\n",
      "train_loss 0.533 val_loss 0.544 val_auc_score 0.835\n",
      "----End of step 0:00:46.497337\n",
      "train_loss 0.523 val_loss 0.551 val_auc_score 0.829\n",
      "----End of step 0:00:48.670641\n",
      "train_loss 0.511 val_loss 0.551 val_auc_score 0.832\n",
      "----End of step 0:00:48.441078\n",
      "train_loss 0.502 val_loss 0.527 val_auc_score 0.838\n",
      "----End of step 0:00:46.504985\n",
      "train_loss 0.494 val_loss 0.530 val_auc_score 0.835\n",
      "----End of step 0:00:47.453408\n",
      "train_loss 0.487 val_loss 0.560 val_auc_score 0.841\n",
      "----End of step 0:00:49.581788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.476 val_loss 0.515 val_auc_score 0.850\n",
      "----End of step 0:00:49.051622\n",
      "train_loss 0.464 val_loss 0.486 val_auc_score 0.861\n",
      "----End of step 0:00:47.583290\n",
      "train_loss 0.455 val_loss 0.487 val_auc_score 0.864\n",
      "----End of step 0:00:46.381396\n",
      "train_loss 0.449 val_loss 0.491 val_auc_score 0.855\n",
      "----End of step 0:00:47.834558\n",
      "train_loss 0.440 val_loss 0.489 val_auc_score 0.861\n",
      "----End of step 0:00:49.849978\n",
      "train_loss 0.438 val_loss 0.494 val_auc_score 0.860\n",
      "----End of step 0:00:49.412206\n",
      "train_loss 0.605 val_loss 0.658 val_auc_score 0.772\n",
      "----End of step 0:00:46.134359\n",
      "train_loss 0.560 val_loss 0.600 val_auc_score 0.784\n",
      "----End of step 0:00:48.615429\n",
      "train_loss 0.546 val_loss 0.598 val_auc_score 0.796\n",
      "----End of step 0:00:48.104343\n",
      "train_loss 0.533 val_loss 0.540 val_auc_score 0.818\n",
      "----End of step 0:00:47.103335\n",
      "train_loss 0.522 val_loss 0.634 val_auc_score 0.810\n",
      "----End of step 0:00:47.101896\n",
      "train_loss 0.513 val_loss 0.568 val_auc_score 0.800\n",
      "----End of step 0:00:47.578293\n",
      "train_loss 0.507 val_loss 0.517 val_auc_score 0.841\n",
      "----End of step 0:00:48.196062\n",
      "train_loss 0.496 val_loss 0.522 val_auc_score 0.849\n",
      "----End of step 0:00:47.648932\n",
      "train_loss 0.485 val_loss 0.501 val_auc_score 0.852\n",
      "----End of step 0:00:48.046558\n",
      "train_loss 0.477 val_loss 0.512 val_auc_score 0.856\n",
      "----End of step 0:00:47.081332\n",
      "train_loss 0.464 val_loss 0.510 val_auc_score 0.848\n",
      "----End of step 0:00:47.872598\n",
      "train_loss 0.455 val_loss 0.515 val_auc_score 0.855\n",
      "----End of step 0:00:48.322281\n",
      "train_loss 0.444 val_loss 0.497 val_auc_score 0.858\n",
      "----End of step 0:00:46.574613\n",
      "train_loss 0.444 val_loss 0.496 val_auc_score 0.859\n",
      "----End of step 0:00:46.672475\n",
      "train_loss 0.439 val_loss 0.495 val_auc_score 0.861\n",
      "----End of step 0:00:46.163471\n",
      "train_loss 0.603 val_loss 0.687 val_auc_score 0.797\n",
      "----End of step 0:00:46.888594\n",
      "train_loss 0.561 val_loss 0.575 val_auc_score 0.799\n",
      "----End of step 0:00:46.463543\n",
      "train_loss 0.545 val_loss 0.556 val_auc_score 0.814\n",
      "----End of step 0:00:46.508887\n",
      "train_loss 0.532 val_loss 0.592 val_auc_score 0.803\n",
      "----End of step 0:00:46.689050\n",
      "train_loss 0.523 val_loss 0.582 val_auc_score 0.836\n",
      "----End of step 0:00:46.236643\n",
      "train_loss 0.514 val_loss 0.523 val_auc_score 0.833\n",
      "----End of step 0:00:46.349560\n",
      "train_loss 0.504 val_loss 0.516 val_auc_score 0.843\n",
      "----End of step 0:00:47.389565\n",
      "train_loss 0.494 val_loss 0.524 val_auc_score 0.837\n",
      "----End of step 0:00:47.497954\n",
      "train_loss 0.486 val_loss 0.577 val_auc_score 0.833\n",
      "----End of step 0:00:47.196516\n",
      "train_loss 0.475 val_loss 0.506 val_auc_score 0.851\n",
      "----End of step 0:00:47.438566\n",
      "train_loss 0.465 val_loss 0.510 val_auc_score 0.847\n",
      "----End of step 0:00:48.397510\n",
      "train_loss 0.457 val_loss 0.501 val_auc_score 0.852\n",
      "----End of step 0:00:47.574458\n",
      "train_loss 0.449 val_loss 0.500 val_auc_score 0.852\n",
      "----End of step 0:00:47.763965\n",
      "train_loss 0.442 val_loss 0.501 val_auc_score 0.856\n",
      "----End of step 0:00:48.208944\n",
      "train_loss 0.440 val_loss 0.502 val_auc_score 0.855\n",
      "----End of step 0:00:47.985960\n",
      "train_loss 0.604 val_loss 0.595 val_auc_score 0.764\n",
      "----End of step 0:00:48.428103\n",
      "train_loss 0.563 val_loss 0.584 val_auc_score 0.786\n",
      "----End of step 0:00:46.953175\n",
      "train_loss 0.544 val_loss 0.607 val_auc_score 0.789\n",
      "----End of step 0:00:47.255761\n",
      "train_loss 0.534 val_loss 0.693 val_auc_score 0.799\n",
      "----End of step 0:00:47.739943\n",
      "train_loss 0.520 val_loss 0.537 val_auc_score 0.817\n",
      "----End of step 0:00:46.681606\n",
      "train_loss 0.512 val_loss 0.548 val_auc_score 0.815\n",
      "----End of step 0:00:47.283781\n",
      "train_loss 0.505 val_loss 0.523 val_auc_score 0.832\n",
      "----End of step 0:00:46.526756\n",
      "train_loss 0.495 val_loss 0.514 val_auc_score 0.840\n",
      "----End of step 0:00:46.979403\n",
      "train_loss 0.487 val_loss 0.521 val_auc_score 0.828\n",
      "----End of step 0:00:47.106976\n",
      "train_loss 0.475 val_loss 0.543 val_auc_score 0.839\n",
      "----End of step 0:00:46.968175\n",
      "train_loss 0.466 val_loss 0.507 val_auc_score 0.852\n",
      "----End of step 0:00:47.441321\n",
      "train_loss 0.455 val_loss 0.524 val_auc_score 0.850\n",
      "----End of step 0:00:47.676032\n",
      "train_loss 0.449 val_loss 0.517 val_auc_score 0.852\n",
      "----End of step 0:00:47.767534\n",
      "train_loss 0.442 val_loss 0.500 val_auc_score 0.856\n",
      "----End of step 0:00:46.713831\n",
      "train_loss 0.439 val_loss 0.499 val_auc_score 0.856\n",
      "----End of step 0:00:47.915997\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.25).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_25_1_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_0_25_full_depth'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.582 val_loss 0.592 val_auc_score 0.795\n",
      "----End of step 0:00:41.029937\n",
      "train_loss 0.540 val_loss 0.627 val_auc_score 0.820\n",
      "----End of step 0:00:41.394671\n",
      "train_loss 0.533 val_loss 0.569 val_auc_score 0.812\n",
      "----End of step 0:00:41.373207\n",
      "train_loss 0.518 val_loss 0.572 val_auc_score 0.783\n",
      "----End of step 0:00:41.785583\n",
      "train_loss 0.508 val_loss 0.539 val_auc_score 0.818\n",
      "----End of step 0:00:41.614770\n",
      "train_loss 0.501 val_loss 0.538 val_auc_score 0.828\n",
      "----End of step 0:00:42.481094\n",
      "train_loss 0.490 val_loss 0.523 val_auc_score 0.841\n",
      "----End of step 0:00:41.800780\n",
      "train_loss 0.480 val_loss 0.524 val_auc_score 0.835\n",
      "----End of step 0:00:42.081729\n",
      "train_loss 0.467 val_loss 0.528 val_auc_score 0.838\n",
      "----End of step 0:00:42.444367\n",
      "train_loss 0.457 val_loss 0.510 val_auc_score 0.844\n",
      "----End of step 0:00:42.042028\n",
      "train_loss 0.444 val_loss 0.494 val_auc_score 0.853\n",
      "----End of step 0:00:41.862604\n",
      "train_loss 0.432 val_loss 0.502 val_auc_score 0.858\n",
      "----End of step 0:00:41.294787\n",
      "train_loss 0.423 val_loss 0.497 val_auc_score 0.859\n",
      "----End of step 0:00:41.952853\n",
      "train_loss 0.415 val_loss 0.507 val_auc_score 0.859\n",
      "----End of step 0:00:42.214710\n",
      "train_loss 0.410 val_loss 0.503 val_auc_score 0.859\n",
      "----End of step 0:00:41.223629\n",
      "train_loss 0.584 val_loss 0.618 val_auc_score 0.814\n",
      "----End of step 0:00:42.038614\n",
      "train_loss 0.541 val_loss 0.590 val_auc_score 0.792\n",
      "----End of step 0:00:41.657168\n",
      "train_loss 0.529 val_loss 0.571 val_auc_score 0.820\n",
      "----End of step 0:00:41.416236\n",
      "train_loss 0.519 val_loss 0.535 val_auc_score 0.828\n",
      "----End of step 0:00:41.182904\n",
      "train_loss 0.508 val_loss 0.551 val_auc_score 0.815\n",
      "----End of step 0:00:41.883404\n",
      "train_loss 0.497 val_loss 0.546 val_auc_score 0.829\n",
      "----End of step 0:00:41.695756\n",
      "train_loss 0.490 val_loss 0.560 val_auc_score 0.837\n",
      "----End of step 0:00:42.018168\n",
      "train_loss 0.477 val_loss 0.580 val_auc_score 0.846\n",
      "----End of step 0:00:41.924754\n",
      "train_loss 0.468 val_loss 0.534 val_auc_score 0.846\n",
      "----End of step 0:00:40.924820\n",
      "train_loss 0.455 val_loss 0.510 val_auc_score 0.844\n",
      "----End of step 0:00:41.894868\n",
      "train_loss 0.443 val_loss 0.511 val_auc_score 0.861\n",
      "----End of step 0:00:42.199908\n",
      "train_loss 0.428 val_loss 0.526 val_auc_score 0.862\n",
      "----End of step 0:00:41.796972\n",
      "train_loss 0.419 val_loss 0.502 val_auc_score 0.868\n",
      "----End of step 0:00:41.499653\n",
      "train_loss 0.414 val_loss 0.496 val_auc_score 0.865\n",
      "----End of step 0:00:42.983235\n",
      "train_loss 0.408 val_loss 0.493 val_auc_score 0.866\n",
      "----End of step 0:00:43.023519\n",
      "train_loss 0.585 val_loss 0.592 val_auc_score 0.800\n",
      "----End of step 0:00:42.210456\n",
      "train_loss 0.542 val_loss 0.565 val_auc_score 0.804\n",
      "----End of step 0:00:42.937179\n",
      "train_loss 0.532 val_loss 0.557 val_auc_score 0.811\n",
      "----End of step 0:00:42.191909\n",
      "train_loss 0.521 val_loss 0.562 val_auc_score 0.834\n",
      "----End of step 0:00:41.980865\n",
      "train_loss 0.510 val_loss 0.539 val_auc_score 0.821\n",
      "----End of step 0:00:41.726034\n",
      "train_loss 0.497 val_loss 0.655 val_auc_score 0.814\n",
      "----End of step 0:00:41.852630\n",
      "train_loss 0.490 val_loss 0.518 val_auc_score 0.834\n",
      "----End of step 0:00:41.563970\n",
      "train_loss 0.479 val_loss 0.503 val_auc_score 0.848\n",
      "----End of step 0:00:41.145830\n",
      "train_loss 0.467 val_loss 0.496 val_auc_score 0.850\n",
      "----End of step 0:00:41.170593\n",
      "train_loss 0.456 val_loss 0.513 val_auc_score 0.858\n",
      "----End of step 0:00:41.956137\n",
      "train_loss 0.446 val_loss 0.499 val_auc_score 0.856\n",
      "----End of step 0:00:42.560790\n",
      "train_loss 0.434 val_loss 0.493 val_auc_score 0.857\n",
      "----End of step 0:00:42.150750\n",
      "train_loss 0.426 val_loss 0.488 val_auc_score 0.865\n",
      "----End of step 0:00:42.787704\n",
      "train_loss 0.416 val_loss 0.503 val_auc_score 0.864\n",
      "----End of step 0:00:42.496363\n",
      "train_loss 0.409 val_loss 0.489 val_auc_score 0.866\n",
      "----End of step 0:00:42.939117\n",
      "train_loss 0.583 val_loss 0.596 val_auc_score 0.780\n",
      "----End of step 0:00:42.931548\n",
      "train_loss 0.541 val_loss 0.584 val_auc_score 0.792\n",
      "----End of step 0:00:43.976904\n",
      "train_loss 0.530 val_loss 0.557 val_auc_score 0.831\n",
      "----End of step 0:00:43.783597\n",
      "train_loss 0.518 val_loss 0.598 val_auc_score 0.803\n",
      "----End of step 0:00:42.264005\n",
      "train_loss 0.509 val_loss 0.510 val_auc_score 0.845\n",
      "----End of step 0:00:42.980709\n",
      "train_loss 0.497 val_loss 0.537 val_auc_score 0.817\n",
      "----End of step 0:00:41.767576\n",
      "train_loss 0.488 val_loss 0.572 val_auc_score 0.841\n",
      "----End of step 0:00:42.163925\n",
      "train_loss 0.480 val_loss 0.531 val_auc_score 0.841\n",
      "----End of step 0:00:42.006059\n",
      "train_loss 0.469 val_loss 0.521 val_auc_score 0.843\n",
      "----End of step 0:00:40.640524\n",
      "train_loss 0.456 val_loss 0.520 val_auc_score 0.852\n",
      "----End of step 0:00:41.649643\n",
      "train_loss 0.444 val_loss 0.496 val_auc_score 0.862\n",
      "----End of step 0:00:41.621290\n",
      "train_loss 0.435 val_loss 0.491 val_auc_score 0.856\n",
      "----End of step 0:00:41.362007\n",
      "train_loss 0.423 val_loss 0.495 val_auc_score 0.865\n",
      "----End of step 0:00:41.358718\n",
      "train_loss 0.415 val_loss 0.486 val_auc_score 0.867\n",
      "----End of step 0:00:41.429727\n",
      "train_loss 0.411 val_loss 0.493 val_auc_score 0.866\n",
      "----End of step 0:00:41.495502\n",
      "train_loss 0.584 val_loss 0.573 val_auc_score 0.794\n",
      "----End of step 0:00:41.515852\n",
      "train_loss 0.541 val_loss 0.668 val_auc_score 0.802\n",
      "----End of step 0:00:41.377284\n",
      "train_loss 0.529 val_loss 0.547 val_auc_score 0.823\n",
      "----End of step 0:00:41.188321\n",
      "train_loss 0.518 val_loss 0.571 val_auc_score 0.800\n",
      "----End of step 0:00:41.924185\n",
      "train_loss 0.510 val_loss 0.538 val_auc_score 0.819\n",
      "----End of step 0:00:40.990273\n",
      "train_loss 0.499 val_loss 0.546 val_auc_score 0.811\n",
      "----End of step 0:00:41.149390\n",
      "train_loss 0.489 val_loss 0.530 val_auc_score 0.833\n",
      "----End of step 0:00:41.397668\n",
      "train_loss 0.479 val_loss 0.504 val_auc_score 0.842\n",
      "----End of step 0:00:40.981445\n",
      "train_loss 0.469 val_loss 0.489 val_auc_score 0.856\n",
      "----End of step 0:00:41.870522\n",
      "train_loss 0.457 val_loss 0.510 val_auc_score 0.855\n",
      "----End of step 0:00:41.449263\n",
      "train_loss 0.443 val_loss 0.504 val_auc_score 0.853\n",
      "----End of step 0:00:41.280403\n",
      "train_loss 0.433 val_loss 0.534 val_auc_score 0.851\n",
      "----End of step 0:00:41.915560\n",
      "train_loss 0.422 val_loss 0.507 val_auc_score 0.855\n",
      "----End of step 0:00:41.482188\n",
      "train_loss 0.414 val_loss 0.495 val_auc_score 0.861\n",
      "----End of step 0:00:41.654257\n",
      "train_loss 0.411 val_loss 0.506 val_auc_score 0.861\n",
      "----End of step 0:00:42.517187\n",
      "train_loss 0.584 val_loss 0.584 val_auc_score 0.791\n",
      "----End of step 0:00:40.536759\n",
      "train_loss 0.545 val_loss 0.638 val_auc_score 0.803\n",
      "----End of step 0:00:40.317307\n",
      "train_loss 0.528 val_loss 0.649 val_auc_score 0.819\n",
      "----End of step 0:00:40.909007\n",
      "train_loss 0.516 val_loss 0.605 val_auc_score 0.796\n",
      "----End of step 0:00:40.784273\n",
      "train_loss 0.508 val_loss 0.559 val_auc_score 0.811\n",
      "----End of step 0:00:41.595054\n",
      "train_loss 0.498 val_loss 0.544 val_auc_score 0.837\n",
      "----End of step 0:00:41.759759\n",
      "train_loss 0.488 val_loss 0.540 val_auc_score 0.825\n",
      "----End of step 0:00:41.780661\n",
      "train_loss 0.481 val_loss 0.526 val_auc_score 0.826\n",
      "----End of step 0:00:41.354628\n",
      "train_loss 0.466 val_loss 0.550 val_auc_score 0.853\n",
      "----End of step 0:00:41.725394\n",
      "train_loss 0.456 val_loss 0.536 val_auc_score 0.859\n",
      "----End of step 0:00:41.058942\n",
      "train_loss 0.445 val_loss 0.495 val_auc_score 0.857\n",
      "----End of step 0:00:40.871612\n",
      "train_loss 0.431 val_loss 0.503 val_auc_score 0.860\n",
      "----End of step 0:00:40.912452\n",
      "train_loss 0.425 val_loss 0.495 val_auc_score 0.858\n",
      "----End of step 0:00:41.140483\n",
      "train_loss 0.415 val_loss 0.497 val_auc_score 0.860\n",
      "----End of step 0:00:41.937590\n",
      "train_loss 0.412 val_loss 0.495 val_auc_score 0.862\n",
      "----End of step 0:00:42.219929\n",
      "train_loss 0.581 val_loss 0.565 val_auc_score 0.803\n",
      "----End of step 0:00:42.539827\n",
      "train_loss 0.544 val_loss 0.587 val_auc_score 0.807\n",
      "----End of step 0:00:42.140437\n",
      "train_loss 0.529 val_loss 0.601 val_auc_score 0.810\n",
      "----End of step 0:00:43.046097\n",
      "train_loss 0.518 val_loss 0.660 val_auc_score 0.795\n",
      "----End of step 0:00:43.446485\n",
      "train_loss 0.507 val_loss 0.553 val_auc_score 0.827\n",
      "----End of step 0:00:41.761690\n",
      "train_loss 0.499 val_loss 0.568 val_auc_score 0.839\n",
      "----End of step 0:00:42.426071\n",
      "train_loss 0.492 val_loss 0.501 val_auc_score 0.849\n",
      "----End of step 0:00:42.678356\n",
      "train_loss 0.482 val_loss 0.520 val_auc_score 0.838\n",
      "----End of step 0:00:42.407186\n",
      "train_loss 0.470 val_loss 0.537 val_auc_score 0.846\n",
      "----End of step 0:00:42.306743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.458 val_loss 0.513 val_auc_score 0.842\n",
      "----End of step 0:00:42.441397\n",
      "train_loss 0.446 val_loss 0.495 val_auc_score 0.857\n",
      "----End of step 0:00:42.034333\n",
      "train_loss 0.434 val_loss 0.506 val_auc_score 0.863\n",
      "----End of step 0:00:43.396990\n",
      "train_loss 0.426 val_loss 0.487 val_auc_score 0.862\n",
      "----End of step 0:00:43.465546\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8647d3ac6a69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n\u001b[1;32m     10\u001b[0m                                        \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                        dataset='mura', binary=True, max_lr=0.01, epochs=15)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mura'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet_0_5_4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Medical_Images/training.py\u001b[0m in \u001b[0;36mtrain_triangular_policy\u001b[0;34m(model, optimizer, train_dl, valid_dl, valid_dataset, loss_fn, dataset, binary, max_lr, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    d = depths[4]\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.5, \n",
    "                     inverted_residual_setting1=d[0], \n",
    "                     inverted_residual_setting2=d[1]).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_4_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_0_5_4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_full_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.5).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_1_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_0_5_full_depth'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_75_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    d = depths[4]\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.75, \n",
    "                     inverted_residual_setting1=d[0], \n",
    "                     inverted_residual_setting2=d[1]).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_4_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_0_75_4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['score', 'time', 'dataset', 'model']\n",
    "df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mura_resnet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
