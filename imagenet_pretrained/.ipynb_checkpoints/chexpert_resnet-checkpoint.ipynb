{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(0)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../architectures.py\n",
    "%run ../prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, valid_dataset = get_chexpert_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 256, 256]), torch.Size([32, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [[[[64, 2], [128, 2]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 2], [128, 2]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 1], [512, 1]]],\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.423 val_loss 0.408 val_auc_score 0.650\n",
      "----End of step 0:01:03.257211\n",
      "train_loss 0.387 val_loss 0.394 val_auc_score 0.693\n",
      "----End of step 0:01:04.589922\n",
      "train_loss 0.377 val_loss 0.393 val_auc_score 0.701\n",
      "----End of step 0:01:04.588734\n",
      "train_loss 0.372 val_loss 0.387 val_auc_score 0.711\n",
      "----End of step 0:01:04.297267\n",
      "train_loss 0.366 val_loss 0.398 val_auc_score 0.713\n",
      "----End of step 0:01:04.051541\n",
      "train_loss 0.363 val_loss 0.399 val_auc_score 0.716\n",
      "----End of step 0:01:03.867801\n",
      "train_loss 0.360 val_loss 0.393 val_auc_score 0.718\n",
      "----End of step 0:01:03.915753\n",
      "train_loss 0.357 val_loss 0.390 val_auc_score 0.717\n",
      "----End of step 0:01:04.212048\n",
      "train_loss 0.354 val_loss 0.387 val_auc_score 0.719\n",
      "----End of step 0:01:04.483231\n",
      "train_loss 0.352 val_loss 0.389 val_auc_score 0.719\n",
      "----End of step 0:01:04.373554\n",
      "train_loss 0.349 val_loss 0.392 val_auc_score 0.719\n",
      "----End of step 0:01:04.717695\n",
      "train_loss 0.348 val_loss 0.389 val_auc_score 0.719\n",
      "----End of step 0:01:03.999565\n",
      "train_loss 0.346 val_loss 0.389 val_auc_score 0.719\n",
      "----End of step 0:01:04.471430\n",
      "train_loss 0.345 val_loss 0.387 val_auc_score 0.720\n",
      "----End of step 0:01:04.500624\n",
      "train_loss 0.344 val_loss 0.390 val_auc_score 0.720\n",
      "----End of step 0:01:04.247964\n",
      "train_loss 0.422 val_loss 0.406 val_auc_score 0.651\n",
      "----End of step 0:01:04.163737\n",
      "train_loss 0.387 val_loss 0.391 val_auc_score 0.692\n",
      "----End of step 0:01:04.052992\n",
      "train_loss 0.377 val_loss 0.390 val_auc_score 0.703\n",
      "----End of step 0:01:03.685257\n",
      "train_loss 0.371 val_loss 0.395 val_auc_score 0.709\n",
      "----End of step 0:01:04.124063\n",
      "train_loss 0.366 val_loss 0.400 val_auc_score 0.708\n",
      "----End of step 0:01:03.794661\n",
      "train_loss 0.363 val_loss 0.385 val_auc_score 0.715\n",
      "----End of step 0:01:04.366705\n",
      "train_loss 0.360 val_loss 0.388 val_auc_score 0.717\n",
      "----End of step 0:01:03.807515\n",
      "train_loss 0.357 val_loss 0.389 val_auc_score 0.715\n",
      "----End of step 0:01:03.686565\n",
      "train_loss 0.355 val_loss 0.394 val_auc_score 0.717\n",
      "----End of step 0:01:04.481811\n",
      "train_loss 0.352 val_loss 0.387 val_auc_score 0.720\n",
      "----End of step 0:01:04.363297\n",
      "train_loss 0.349 val_loss 0.395 val_auc_score 0.719\n",
      "----End of step 0:01:04.031917\n",
      "train_loss 0.347 val_loss 0.390 val_auc_score 0.718\n",
      "----End of step 0:01:03.915708\n",
      "train_loss 0.345 val_loss 0.389 val_auc_score 0.719\n",
      "----End of step 0:01:04.542222\n",
      "train_loss 0.345 val_loss 0.390 val_auc_score 0.719\n",
      "----End of step 0:01:04.316303\n",
      "train_loss 0.344 val_loss 0.390 val_auc_score 0.719\n",
      "----End of step 0:01:04.561459\n",
      "train_loss 0.421 val_loss 0.406 val_auc_score 0.656\n",
      "----End of step 0:01:04.234607\n",
      "train_loss 0.387 val_loss 0.390 val_auc_score 0.697\n",
      "----End of step 0:01:03.989331\n",
      "train_loss 0.377 val_loss 0.391 val_auc_score 0.704\n",
      "----End of step 0:01:04.245492\n",
      "train_loss 0.371 val_loss 0.389 val_auc_score 0.710\n",
      "----End of step 0:01:04.484875\n",
      "train_loss 0.367 val_loss 0.385 val_auc_score 0.713\n",
      "----End of step 0:01:04.656293\n",
      "train_loss 0.362 val_loss 0.389 val_auc_score 0.715\n",
      "----End of step 0:01:04.829706\n",
      "train_loss 0.359 val_loss 0.385 val_auc_score 0.716\n",
      "----End of step 0:01:03.580972\n",
      "train_loss 0.357 val_loss 0.384 val_auc_score 0.719\n",
      "----End of step 0:01:04.464312\n",
      "train_loss 0.354 val_loss 0.383 val_auc_score 0.718\n",
      "----End of step 0:01:04.336960\n",
      "train_loss 0.351 val_loss 0.390 val_auc_score 0.716\n",
      "----End of step 0:01:04.044709\n",
      "train_loss 0.349 val_loss 0.387 val_auc_score 0.719\n",
      "----End of step 0:01:04.220759\n",
      "train_loss 0.347 val_loss 0.392 val_auc_score 0.718\n",
      "----End of step 0:01:04.658607\n",
      "train_loss 0.345 val_loss 0.387 val_auc_score 0.718\n",
      "----End of step 0:01:04.630166\n",
      "train_loss 0.344 val_loss 0.388 val_auc_score 0.718\n",
      "----End of step 0:01:03.192751\n",
      "train_loss 0.344 val_loss 0.389 val_auc_score 0.717\n",
      "----End of step 0:01:02.391946\n",
      "train_loss 0.421 val_loss 0.406 val_auc_score 0.655\n",
      "----End of step 0:01:02.095174\n",
      "train_loss 0.387 val_loss 0.397 val_auc_score 0.693\n",
      "----End of step 0:01:01.311274\n",
      "train_loss 0.377 val_loss 0.388 val_auc_score 0.700\n",
      "----End of step 0:01:02.685532\n",
      "train_loss 0.370 val_loss 0.387 val_auc_score 0.709\n",
      "----End of step 0:01:03.336817\n",
      "train_loss 0.367 val_loss 0.396 val_auc_score 0.716\n",
      "----End of step 0:01:03.089583\n",
      "train_loss 0.363 val_loss 0.387 val_auc_score 0.712\n",
      "----End of step 0:01:03.107806\n",
      "train_loss 0.360 val_loss 0.389 val_auc_score 0.716\n",
      "----End of step 0:01:03.991820\n",
      "train_loss 0.357 val_loss 0.386 val_auc_score 0.719\n",
      "----End of step 0:01:03.141065\n",
      "train_loss 0.355 val_loss 0.391 val_auc_score 0.721\n",
      "----End of step 0:01:02.377305\n",
      "train_loss 0.352 val_loss 0.388 val_auc_score 0.720\n",
      "----End of step 0:01:03.532767\n",
      "train_loss 0.350 val_loss 0.388 val_auc_score 0.720\n",
      "----End of step 0:01:03.568578\n",
      "train_loss 0.348 val_loss 0.391 val_auc_score 0.719\n",
      "----End of step 0:01:03.358982\n",
      "train_loss 0.345 val_loss 0.390 val_auc_score 0.719\n",
      "----End of step 0:01:05.296485\n",
      "train_loss 0.345 val_loss 0.389 val_auc_score 0.719\n",
      "----End of step 0:01:04.366371\n",
      "train_loss 0.344 val_loss 0.388 val_auc_score 0.720\n",
      "----End of step 0:01:05.696186\n",
      "train_loss 0.422 val_loss 0.407 val_auc_score 0.652\n",
      "----End of step 0:01:04.725994\n",
      "train_loss 0.387 val_loss 0.395 val_auc_score 0.696\n",
      "----End of step 0:01:05.173507\n",
      "train_loss 0.377 val_loss 0.394 val_auc_score 0.702\n",
      "----End of step 0:01:06.103819\n",
      "train_loss 0.371 val_loss 0.389 val_auc_score 0.708\n",
      "----End of step 0:01:05.178535\n",
      "train_loss 0.367 val_loss 0.385 val_auc_score 0.711\n",
      "----End of step 0:01:06.049067\n",
      "train_loss 0.363 val_loss 0.397 val_auc_score 0.710\n",
      "----End of step 0:01:08.150939\n",
      "train_loss 0.360 val_loss 0.388 val_auc_score 0.712\n",
      "----End of step 0:01:06.247213\n",
      "train_loss 0.357 val_loss 0.385 val_auc_score 0.716\n",
      "----End of step 0:01:07.107471\n",
      "train_loss 0.355 val_loss 0.384 val_auc_score 0.718\n",
      "----End of step 0:01:04.326564\n",
      "train_loss 0.352 val_loss 0.388 val_auc_score 0.714\n",
      "----End of step 0:01:08.696682\n",
      "train_loss 0.349 val_loss 0.388 val_auc_score 0.715\n",
      "----End of step 0:01:04.298091\n",
      "train_loss 0.347 val_loss 0.387 val_auc_score 0.716\n",
      "----End of step 0:01:08.602847\n",
      "train_loss 0.346 val_loss 0.387 val_auc_score 0.717\n",
      "----End of step 0:01:05.139500\n",
      "train_loss 0.344 val_loss 0.389 val_auc_score 0.717\n",
      "----End of step 0:01:05.311196\n",
      "train_loss 0.344 val_loss 0.388 val_auc_score 0.717\n",
      "----End of step 0:01:04.428130\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(5):\n",
    "    model = resnet18(block=depthwise_block, num_classes=1000).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/model_320_iter20_770.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=5, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                               loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                               dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'chexpert', 'resnet_full'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.25_full_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.431 val_loss 0.446 val_auc_score 0.614\n",
      "----End of step 0:01:06.507949\n",
      "train_loss 0.401 val_loss 0.426 val_auc_score 0.649\n",
      "----End of step 0:01:05.827140\n",
      "train_loss 0.391 val_loss 0.425 val_auc_score 0.663\n",
      "----End of step 0:01:09.313933\n",
      "train_loss 0.386 val_loss 0.436 val_auc_score 0.670\n",
      "----End of step 0:01:07.126550\n",
      "train_loss 0.382 val_loss 0.436 val_auc_score 0.674\n",
      "----End of step 0:01:06.511960\n",
      "train_loss 0.380 val_loss 0.446 val_auc_score 0.676\n",
      "----End of step 0:01:06.839588\n",
      "train_loss 0.377 val_loss 0.464 val_auc_score 0.671\n",
      "----End of step 0:01:07.193239\n",
      "train_loss 0.375 val_loss 0.457 val_auc_score 0.680\n",
      "----End of step 0:01:06.200017\n",
      "train_loss 0.374 val_loss 0.445 val_auc_score 0.679\n",
      "----End of step 0:01:06.158409\n",
      "train_loss 0.373 val_loss 0.471 val_auc_score 0.682\n",
      "----End of step 0:01:05.152611\n",
      "train_loss 0.372 val_loss 0.456 val_auc_score 0.681\n",
      "----End of step 0:01:05.729308\n",
      "train_loss 0.371 val_loss 0.474 val_auc_score 0.681\n",
      "----End of step 0:01:05.084619\n",
      "train_loss 0.370 val_loss 0.467 val_auc_score 0.683\n",
      "----End of step 0:01:06.201488\n",
      "train_loss 0.370 val_loss 0.467 val_auc_score 0.683\n",
      "----End of step 0:01:07.371460\n",
      "train_loss 0.369 val_loss 0.471 val_auc_score 0.683\n",
      "----End of step 0:01:05.882596\n",
      "train_loss 0.432 val_loss 0.455 val_auc_score 0.609\n",
      "----End of step 0:01:07.487112\n",
      "train_loss 0.401 val_loss 0.442 val_auc_score 0.650\n",
      "----End of step 0:01:06.681429\n",
      "train_loss 0.391 val_loss 0.441 val_auc_score 0.664\n",
      "----End of step 0:01:05.167482\n",
      "train_loss 0.386 val_loss 0.454 val_auc_score 0.660\n",
      "----End of step 0:01:06.394365\n",
      "train_loss 0.382 val_loss 0.435 val_auc_score 0.664\n",
      "----End of step 0:01:08.524737\n",
      "train_loss 0.380 val_loss 0.433 val_auc_score 0.665\n",
      "----End of step 0:01:06.519495\n",
      "train_loss 0.377 val_loss 0.442 val_auc_score 0.665\n",
      "----End of step 0:01:06.351099\n",
      "train_loss 0.376 val_loss 0.435 val_auc_score 0.670\n",
      "----End of step 0:01:07.594052\n",
      "train_loss 0.375 val_loss 0.440 val_auc_score 0.672\n",
      "----End of step 0:01:05.892025\n",
      "train_loss 0.374 val_loss 0.434 val_auc_score 0.672\n",
      "----End of step 0:01:05.009896\n",
      "train_loss 0.372 val_loss 0.451 val_auc_score 0.674\n",
      "----End of step 0:01:04.360657\n",
      "train_loss 0.372 val_loss 0.443 val_auc_score 0.675\n",
      "----End of step 0:01:06.138253\n",
      "train_loss 0.371 val_loss 0.457 val_auc_score 0.674\n",
      "----End of step 0:01:05.899946\n",
      "train_loss 0.370 val_loss 0.447 val_auc_score 0.674\n",
      "----End of step 0:01:04.284512\n",
      "train_loss 0.369 val_loss 0.452 val_auc_score 0.674\n",
      "----End of step 0:01:06.586310\n",
      "train_loss 0.432 val_loss 0.477 val_auc_score 0.611\n",
      "----End of step 0:01:04.485705\n",
      "train_loss 0.401 val_loss 0.440 val_auc_score 0.647\n",
      "----End of step 0:01:06.627728\n",
      "train_loss 0.392 val_loss 0.452 val_auc_score 0.660\n",
      "----End of step 0:01:06.354007\n",
      "train_loss 0.386 val_loss 0.454 val_auc_score 0.664\n",
      "----End of step 0:01:03.557013\n",
      "train_loss 0.383 val_loss 0.436 val_auc_score 0.670\n",
      "----End of step 0:01:06.235054\n",
      "train_loss 0.380 val_loss 0.450 val_auc_score 0.673\n",
      "----End of step 0:01:07.264028\n",
      "train_loss 0.378 val_loss 0.454 val_auc_score 0.667\n",
      "----End of step 0:01:06.758590\n",
      "train_loss 0.376 val_loss 0.456 val_auc_score 0.670\n",
      "----End of step 0:01:04.795208\n",
      "train_loss 0.375 val_loss 0.478 val_auc_score 0.662\n",
      "----End of step 0:01:04.381790\n",
      "train_loss 0.373 val_loss 0.470 val_auc_score 0.664\n",
      "----End of step 0:01:06.081816\n",
      "train_loss 0.372 val_loss 0.458 val_auc_score 0.665\n",
      "----End of step 0:01:06.006946\n",
      "train_loss 0.372 val_loss 0.478 val_auc_score 0.665\n",
      "----End of step 0:01:03.781635\n",
      "train_loss 0.371 val_loss 0.469 val_auc_score 0.668\n",
      "----End of step 0:01:04.917828\n",
      "train_loss 0.370 val_loss 0.465 val_auc_score 0.667\n",
      "----End of step 0:01:07.522715\n",
      "train_loss 0.370 val_loss 0.465 val_auc_score 0.667\n",
      "----End of step 0:01:06.477694\n",
      "train_loss 0.434 val_loss 0.476 val_auc_score 0.613\n",
      "----End of step 0:01:05.380749\n",
      "train_loss 0.401 val_loss 0.487 val_auc_score 0.657\n",
      "----End of step 0:01:07.625513\n",
      "train_loss 0.391 val_loss 0.474 val_auc_score 0.668\n",
      "----End of step 0:01:05.364684\n",
      "train_loss 0.386 val_loss 0.480 val_auc_score 0.671\n",
      "----End of step 0:01:04.529184\n",
      "train_loss 0.382 val_loss 0.511 val_auc_score 0.672\n",
      "----End of step 0:01:03.973097\n",
      "train_loss 0.380 val_loss 0.461 val_auc_score 0.671\n",
      "----End of step 0:01:08.331627\n",
      "train_loss 0.378 val_loss 0.446 val_auc_score 0.676\n",
      "----End of step 0:01:07.571503\n",
      "train_loss 0.376 val_loss 0.481 val_auc_score 0.673\n",
      "----End of step 0:01:05.798034\n",
      "train_loss 0.374 val_loss 0.488 val_auc_score 0.674\n",
      "----End of step 0:01:06.722396\n",
      "train_loss 0.373 val_loss 0.528 val_auc_score 0.678\n",
      "----End of step 0:01:04.030275\n",
      "train_loss 0.372 val_loss 0.501 val_auc_score 0.679\n",
      "----End of step 0:01:05.149082\n",
      "train_loss 0.371 val_loss 0.518 val_auc_score 0.679\n",
      "----End of step 0:01:04.696648\n",
      "train_loss 0.370 val_loss 0.507 val_auc_score 0.679\n",
      "----End of step 0:01:05.342159\n",
      "train_loss 0.370 val_loss 0.506 val_auc_score 0.680\n",
      "----End of step 0:01:06.236279\n",
      "train_loss 0.369 val_loss 0.513 val_auc_score 0.679\n",
      "----End of step 0:01:05.812289\n",
      "train_loss 0.433 val_loss 0.480 val_auc_score 0.607\n",
      "----End of step 0:01:05.110509\n",
      "train_loss 0.400 val_loss 0.481 val_auc_score 0.647\n",
      "----End of step 0:01:05.287252\n",
      "train_loss 0.391 val_loss 0.474 val_auc_score 0.661\n",
      "----End of step 0:01:04.103602\n",
      "train_loss 0.385 val_loss 0.494 val_auc_score 0.664\n",
      "----End of step 0:01:04.562949\n",
      "train_loss 0.382 val_loss 0.510 val_auc_score 0.665\n",
      "----End of step 0:01:04.734548\n",
      "train_loss 0.380 val_loss 0.459 val_auc_score 0.669\n",
      "----End of step 0:01:05.552955\n",
      "train_loss 0.377 val_loss 0.453 val_auc_score 0.671\n",
      "----End of step 0:01:02.241646\n",
      "train_loss 0.376 val_loss 0.493 val_auc_score 0.668\n",
      "----End of step 0:01:03.345598\n",
      "train_loss 0.374 val_loss 0.496 val_auc_score 0.669\n",
      "----End of step 0:01:03.046790\n",
      "train_loss 0.372 val_loss 0.511 val_auc_score 0.668\n",
      "----End of step 0:01:02.749275\n",
      "train_loss 0.372 val_loss 0.490 val_auc_score 0.670\n",
      "----End of step 0:01:02.093267\n",
      "train_loss 0.371 val_loss 0.473 val_auc_score 0.674\n",
      "----End of step 0:01:01.866594\n",
      "train_loss 0.370 val_loss 0.476 val_auc_score 0.673\n",
      "----End of step 0:01:02.930617\n",
      "train_loss 0.370 val_loss 0.472 val_auc_score 0.673\n",
      "----End of step 0:01:02.401135\n",
      "train_loss 0.369 val_loss 0.475 val_auc_score 0.673\n",
      "----End of step 0:01:01.966846\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.25).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_25_1_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=5, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'chexpert', 'resnet_0_25_full_depth'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([32, 5])) must be the same as input size (torch.Size([32, 1]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-944ce36d1c33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n\u001b[1;32m     10\u001b[0m                                        \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                        dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chexpert'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet_0_5_4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Medical_Images/training.py\u001b[0m in \u001b[0;36mtrain_triangular_policy\u001b[0;34m(model, optimizer, train_dl, valid_dl, valid_dataset, loss_fn, dataset, binary, max_lr, epochs)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2111\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2112\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32, 5])) must be the same as input size (torch.Size([32, 1]))"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    d = depths[4]\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.5, \n",
    "                     inverted_residual_setting1=d[0], \n",
    "                     inverted_residual_setting2=d[1]).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_4_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=5, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'chexpert', 'resnet_0_5_4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_full_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.5).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_1_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=5, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'chexpert', 'resnet_0_5_full_depth'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_75_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    d = depths[4]\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.75, \n",
    "                     inverted_residual_setting1=d[0], \n",
    "                     inverted_residual_setting2=d[1]).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_4_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=5, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.001)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='chexpert', binary=False, max_lr=0.001, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'chexpert', 'resnet_0_75_4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['score', 'time', 'dataset', 'model']\n",
    "df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"chexpert_resnet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
