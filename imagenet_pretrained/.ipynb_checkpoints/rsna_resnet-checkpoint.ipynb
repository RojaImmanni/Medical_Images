{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(6)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../architectures.py\n",
    "%run ../prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, valid_dataset = rsna_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 256, 256]), torch.Size([32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [[[[64, 2], [128, 2]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 2], [128, 2]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 1], [512, 1]]],\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.383 val_loss 0.365 val_auc_score 0.913\n",
      "----End of step 0:01:05.679331\n",
      "train_loss 0.336 val_loss 0.345 val_auc_score 0.915\n",
      "----End of step 0:01:06.794483\n",
      "train_loss 0.326 val_loss 0.317 val_auc_score 0.930\n",
      "----End of step 0:01:05.635834\n",
      "train_loss 0.309 val_loss 0.319 val_auc_score 0.934\n",
      "----End of step 0:01:06.165916\n",
      "train_loss 0.295 val_loss 0.299 val_auc_score 0.935\n",
      "----End of step 0:01:06.397771\n",
      "train_loss 0.283 val_loss 0.282 val_auc_score 0.943\n",
      "----End of step 0:01:06.096675\n",
      "train_loss 0.278 val_loss 0.271 val_auc_score 0.947\n",
      "----End of step 0:01:05.809947\n",
      "train_loss 0.265 val_loss 0.276 val_auc_score 0.944\n",
      "----End of step 0:01:06.107688\n",
      "train_loss 0.255 val_loss 0.257 val_auc_score 0.952\n",
      "----End of step 0:01:06.602247\n",
      "train_loss 0.239 val_loss 0.253 val_auc_score 0.955\n",
      "----End of step 0:01:05.946790\n",
      "train_loss 0.233 val_loss 0.249 val_auc_score 0.956\n",
      "----End of step 0:01:06.374055\n",
      "train_loss 0.221 val_loss 0.247 val_auc_score 0.957\n",
      "----End of step 0:01:05.782258\n",
      "train_loss 0.209 val_loss 0.251 val_auc_score 0.958\n",
      "----End of step 0:01:05.361312\n",
      "train_loss 0.202 val_loss 0.247 val_auc_score 0.959\n",
      "----End of step 0:01:05.073078\n",
      "train_loss 0.199 val_loss 0.246 val_auc_score 0.959\n",
      "----End of step 0:01:05.578946\n",
      "train_loss 0.385 val_loss 0.334 val_auc_score 0.917\n",
      "----End of step 0:01:06.040495\n",
      "train_loss 0.340 val_loss 0.359 val_auc_score 0.909\n",
      "----End of step 0:01:06.809949\n",
      "train_loss 0.327 val_loss 0.303 val_auc_score 0.932\n",
      "----End of step 0:01:04.976903\n",
      "train_loss 0.309 val_loss 0.306 val_auc_score 0.930\n",
      "----End of step 0:01:06.096949\n",
      "train_loss 0.296 val_loss 0.296 val_auc_score 0.937\n",
      "----End of step 0:01:05.618309\n",
      "train_loss 0.287 val_loss 0.284 val_auc_score 0.941\n",
      "----End of step 0:01:05.862868\n",
      "train_loss 0.277 val_loss 0.266 val_auc_score 0.948\n",
      "----End of step 0:01:06.179627\n",
      "train_loss 0.262 val_loss 0.269 val_auc_score 0.948\n",
      "----End of step 0:01:05.109014\n",
      "train_loss 0.253 val_loss 0.260 val_auc_score 0.951\n",
      "----End of step 0:01:07.516107\n",
      "train_loss 0.242 val_loss 0.256 val_auc_score 0.953\n",
      "----End of step 0:01:05.894543\n",
      "train_loss 0.230 val_loss 0.248 val_auc_score 0.956\n",
      "----End of step 0:01:06.176765\n",
      "train_loss 0.220 val_loss 0.254 val_auc_score 0.955\n",
      "----End of step 0:01:08.977251\n",
      "train_loss 0.211 val_loss 0.248 val_auc_score 0.958\n",
      "----End of step 0:01:05.884682\n",
      "train_loss 0.203 val_loss 0.243 val_auc_score 0.958\n",
      "----End of step 0:01:05.401493\n",
      "train_loss 0.198 val_loss 0.247 val_auc_score 0.958\n",
      "----End of step 0:01:05.970906\n",
      "train_loss 0.385 val_loss 0.346 val_auc_score 0.914\n",
      "----End of step 0:01:06.481760\n",
      "train_loss 0.337 val_loss 0.350 val_auc_score 0.925\n",
      "----End of step 0:01:06.019857\n",
      "train_loss 0.329 val_loss 0.336 val_auc_score 0.927\n",
      "----End of step 0:01:05.693496\n",
      "train_loss 0.307 val_loss 0.321 val_auc_score 0.931\n",
      "----End of step 0:01:05.705688\n",
      "train_loss 0.296 val_loss 0.294 val_auc_score 0.935\n",
      "----End of step 0:01:06.330987\n",
      "train_loss 0.288 val_loss 0.289 val_auc_score 0.941\n",
      "----End of step 0:01:05.304633\n",
      "train_loss 0.277 val_loss 0.276 val_auc_score 0.945\n",
      "----End of step 0:01:05.049139\n",
      "train_loss 0.268 val_loss 0.280 val_auc_score 0.942\n",
      "----End of step 0:01:06.532169\n",
      "train_loss 0.254 val_loss 0.265 val_auc_score 0.949\n",
      "----End of step 0:01:05.820546\n",
      "train_loss 0.242 val_loss 0.264 val_auc_score 0.951\n",
      "----End of step 0:01:05.676088\n",
      "train_loss 0.233 val_loss 0.250 val_auc_score 0.955\n",
      "----End of step 0:01:05.189580\n",
      "train_loss 0.220 val_loss 0.253 val_auc_score 0.956\n",
      "----End of step 0:01:05.313727\n",
      "train_loss 0.211 val_loss 0.251 val_auc_score 0.958\n",
      "----End of step 0:01:05.440487\n",
      "train_loss 0.203 val_loss 0.247 val_auc_score 0.958\n",
      "----End of step 0:01:03.532592\n",
      "train_loss 0.201 val_loss 0.245 val_auc_score 0.959\n",
      "----End of step 0:01:04.056732\n",
      "train_loss 0.383 val_loss 0.392 val_auc_score 0.920\n",
      "----End of step 0:01:05.677910\n",
      "train_loss 0.344 val_loss 0.324 val_auc_score 0.924\n",
      "----End of step 0:01:06.680225\n",
      "train_loss 0.327 val_loss 0.331 val_auc_score 0.927\n",
      "----End of step 0:01:07.792138\n",
      "train_loss 0.311 val_loss 0.320 val_auc_score 0.930\n",
      "----End of step 0:01:05.602402\n",
      "train_loss 0.295 val_loss 0.319 val_auc_score 0.927\n",
      "----End of step 0:01:05.410959\n",
      "train_loss 0.287 val_loss 0.290 val_auc_score 0.944\n",
      "----End of step 0:01:07.243228\n",
      "train_loss 0.275 val_loss 0.274 val_auc_score 0.945\n",
      "----End of step 0:01:05.963175\n",
      "train_loss 0.266 val_loss 0.267 val_auc_score 0.948\n",
      "----End of step 0:01:05.002037\n",
      "train_loss 0.254 val_loss 0.261 val_auc_score 0.950\n",
      "----End of step 0:01:05.477597\n",
      "train_loss 0.240 val_loss 0.259 val_auc_score 0.954\n",
      "----End of step 0:01:06.643145\n",
      "train_loss 0.233 val_loss 0.263 val_auc_score 0.954\n",
      "----End of step 0:01:07.874656\n",
      "train_loss 0.221 val_loss 0.256 val_auc_score 0.956\n",
      "----End of step 0:01:07.519465\n",
      "train_loss 0.212 val_loss 0.244 val_auc_score 0.958\n",
      "----End of step 0:01:07.899019\n",
      "train_loss 0.200 val_loss 0.245 val_auc_score 0.959\n",
      "----End of step 0:01:09.363194\n",
      "train_loss 0.200 val_loss 0.246 val_auc_score 0.959\n",
      "----End of step 0:01:07.744498\n",
      "train_loss 0.384 val_loss 0.343 val_auc_score 0.916\n",
      "----End of step 0:01:09.410966\n",
      "train_loss 0.341 val_loss 0.350 val_auc_score 0.921\n",
      "----End of step 0:01:08.413510\n",
      "train_loss 0.323 val_loss 0.305 val_auc_score 0.933\n",
      "----End of step 0:01:07.932114\n",
      "train_loss 0.312 val_loss 0.310 val_auc_score 0.931\n",
      "----End of step 0:01:07.334843\n",
      "train_loss 0.297 val_loss 0.312 val_auc_score 0.939\n",
      "----End of step 0:01:06.021376\n",
      "train_loss 0.287 val_loss 0.283 val_auc_score 0.942\n",
      "----End of step 0:01:07.000606\n",
      "train_loss 0.276 val_loss 0.320 val_auc_score 0.939\n",
      "----End of step 0:01:06.280072\n",
      "train_loss 0.267 val_loss 0.275 val_auc_score 0.947\n",
      "----End of step 0:01:06.504970\n",
      "train_loss 0.255 val_loss 0.263 val_auc_score 0.949\n",
      "----End of step 0:01:06.288625\n",
      "train_loss 0.243 val_loss 0.258 val_auc_score 0.951\n",
      "----End of step 0:01:06.973458\n",
      "train_loss 0.231 val_loss 0.254 val_auc_score 0.955\n",
      "----End of step 0:01:09.597766\n",
      "train_loss 0.223 val_loss 0.249 val_auc_score 0.956\n",
      "----End of step 0:01:07.387846\n",
      "train_loss 0.212 val_loss 0.244 val_auc_score 0.958\n",
      "----End of step 0:01:08.072964\n",
      "train_loss 0.203 val_loss 0.244 val_auc_score 0.958\n",
      "----End of step 0:01:07.152462\n",
      "train_loss 0.199 val_loss 0.247 val_auc_score 0.958\n",
      "----End of step 0:01:08.708738\n",
      "train_loss 0.387 val_loss 0.375 val_auc_score 0.914\n",
      "----End of step 0:01:07.324623\n",
      "train_loss 0.337 val_loss 0.399 val_auc_score 0.920\n",
      "----End of step 0:01:08.979623\n",
      "train_loss 0.324 val_loss 0.324 val_auc_score 0.932\n",
      "----End of step 0:01:07.343301\n",
      "train_loss 0.312 val_loss 0.376 val_auc_score 0.932\n",
      "----End of step 0:01:07.536930\n",
      "train_loss 0.299 val_loss 0.472 val_auc_score 0.916\n",
      "----End of step 0:01:08.229066\n",
      "train_loss 0.286 val_loss 0.293 val_auc_score 0.942\n",
      "----End of step 0:01:09.110797\n",
      "train_loss 0.279 val_loss 0.294 val_auc_score 0.942\n",
      "----End of step 0:01:07.826613\n",
      "train_loss 0.266 val_loss 0.291 val_auc_score 0.947\n",
      "----End of step 0:01:07.654958\n",
      "train_loss 0.255 val_loss 0.257 val_auc_score 0.953\n",
      "----End of step 0:01:08.126904\n",
      "train_loss 0.243 val_loss 0.269 val_auc_score 0.952\n",
      "----End of step 0:01:11.515020\n",
      "train_loss 0.232 val_loss 0.250 val_auc_score 0.955\n",
      "----End of step 0:01:08.686971\n",
      "train_loss 0.221 val_loss 0.252 val_auc_score 0.957\n",
      "----End of step 0:01:07.443932\n",
      "train_loss 0.213 val_loss 0.249 val_auc_score 0.958\n",
      "----End of step 0:01:08.061194\n",
      "train_loss 0.203 val_loss 0.245 val_auc_score 0.958\n",
      "----End of step 0:01:07.731705\n",
      "train_loss 0.199 val_loss 0.245 val_auc_score 0.959\n",
      "----End of step 0:01:06.391994\n",
      "train_loss 0.390 val_loss 0.348 val_auc_score 0.910\n",
      "----End of step 0:01:08.784706\n",
      "train_loss 0.341 val_loss 0.336 val_auc_score 0.921\n",
      "----End of step 0:01:07.615315\n",
      "train_loss 0.325 val_loss 0.315 val_auc_score 0.933\n",
      "----End of step 0:01:08.416958\n",
      "train_loss 0.308 val_loss 0.314 val_auc_score 0.931\n",
      "----End of step 0:01:10.266466\n",
      "train_loss 0.299 val_loss 0.294 val_auc_score 0.940\n",
      "----End of step 0:01:08.187958\n",
      "train_loss 0.289 val_loss 0.289 val_auc_score 0.941\n",
      "----End of step 0:01:09.350657\n",
      "train_loss 0.280 val_loss 0.276 val_auc_score 0.945\n",
      "----End of step 0:01:08.557160\n",
      "train_loss 0.265 val_loss 0.275 val_auc_score 0.948\n",
      "----End of step 0:01:08.303155\n",
      "train_loss 0.258 val_loss 0.277 val_auc_score 0.947\n",
      "----End of step 0:01:11.480366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.242 val_loss 0.261 val_auc_score 0.952\n",
      "----End of step 0:01:07.585836\n",
      "train_loss 0.231 val_loss 0.255 val_auc_score 0.954\n",
      "----End of step 0:01:08.320987\n",
      "train_loss 0.222 val_loss 0.253 val_auc_score 0.956\n",
      "----End of step 0:01:10.939645\n",
      "train_loss 0.214 val_loss 0.247 val_auc_score 0.958\n",
      "----End of step 0:01:10.280193\n",
      "train_loss 0.203 val_loss 0.247 val_auc_score 0.958\n",
      "----End of step 0:01:07.814992\n",
      "train_loss 0.200 val_loss 0.247 val_auc_score 0.958\n",
      "----End of step 0:01:08.483399\n",
      "train_loss 0.385 val_loss 0.351 val_auc_score 0.918\n",
      "----End of step 0:01:07.830344\n",
      "train_loss 0.336 val_loss 0.330 val_auc_score 0.922\n",
      "----End of step 0:01:06.870056\n",
      "train_loss 0.324 val_loss 0.500 val_auc_score 0.907\n",
      "----End of step 0:01:09.139648\n",
      "train_loss 0.309 val_loss 0.331 val_auc_score 0.930\n",
      "----End of step 0:01:08.137526\n",
      "train_loss 0.295 val_loss 0.293 val_auc_score 0.937\n",
      "----End of step 0:01:07.468994\n",
      "train_loss 0.285 val_loss 0.289 val_auc_score 0.941\n",
      "----End of step 0:01:09.645158\n",
      "train_loss 0.275 val_loss 0.296 val_auc_score 0.941\n",
      "----End of step 0:01:10.856922\n",
      "train_loss 0.266 val_loss 0.271 val_auc_score 0.947\n",
      "----End of step 0:01:10.796999\n",
      "train_loss 0.252 val_loss 0.260 val_auc_score 0.951\n",
      "----End of step 0:01:09.154363\n",
      "train_loss 0.243 val_loss 0.254 val_auc_score 0.954\n",
      "----End of step 0:01:09.245428\n",
      "train_loss 0.231 val_loss 0.257 val_auc_score 0.954\n",
      "----End of step 0:01:11.263191\n",
      "train_loss 0.220 val_loss 0.245 val_auc_score 0.957\n",
      "----End of step 0:01:07.698369\n",
      "train_loss 0.210 val_loss 0.248 val_auc_score 0.958\n",
      "----End of step 0:01:07.616204\n",
      "train_loss 0.201 val_loss 0.247 val_auc_score 0.959\n",
      "----End of step 0:01:11.926980\n",
      "train_loss 0.199 val_loss 0.246 val_auc_score 0.959\n",
      "----End of step 0:01:11.321548\n",
      "train_loss 0.385 val_loss 0.358 val_auc_score 0.914\n",
      "----End of step 0:01:06.982935\n",
      "train_loss 0.339 val_loss 0.344 val_auc_score 0.918\n",
      "----End of step 0:01:07.591354\n",
      "train_loss 0.325 val_loss 0.386 val_auc_score 0.914\n",
      "----End of step 0:01:08.151339\n",
      "train_loss 0.309 val_loss 0.336 val_auc_score 0.923\n",
      "----End of step 0:01:09.055874\n",
      "train_loss 0.300 val_loss 0.320 val_auc_score 0.930\n",
      "----End of step 0:01:06.360362\n",
      "train_loss 0.286 val_loss 0.290 val_auc_score 0.940\n",
      "----End of step 0:01:08.972499\n",
      "train_loss 0.275 val_loss 0.292 val_auc_score 0.944\n",
      "----End of step 0:01:07.915650\n",
      "train_loss 0.265 val_loss 0.271 val_auc_score 0.948\n",
      "----End of step 0:01:09.596867\n",
      "train_loss 0.253 val_loss 0.264 val_auc_score 0.950\n",
      "----End of step 0:01:09.147052\n",
      "train_loss 0.243 val_loss 0.257 val_auc_score 0.954\n",
      "----End of step 0:01:10.542105\n",
      "train_loss 0.231 val_loss 0.259 val_auc_score 0.955\n",
      "----End of step 0:01:06.327509\n",
      "train_loss 0.222 val_loss 0.249 val_auc_score 0.957\n",
      "----End of step 0:01:06.870995\n",
      "train_loss 0.213 val_loss 0.242 val_auc_score 0.959\n",
      "----End of step 0:01:09.968807\n",
      "train_loss 0.204 val_loss 0.244 val_auc_score 0.959\n",
      "----End of step 0:01:06.784151\n",
      "train_loss 0.201 val_loss 0.244 val_auc_score 0.959\n",
      "----End of step 0:01:09.391556\n",
      "train_loss 0.389 val_loss 0.434 val_auc_score 0.912\n",
      "----End of step 0:01:06.021350\n",
      "train_loss 0.343 val_loss 0.325 val_auc_score 0.923\n",
      "----End of step 0:01:05.970472\n",
      "train_loss 0.324 val_loss 0.316 val_auc_score 0.927\n",
      "----End of step 0:01:05.723790\n",
      "train_loss 0.312 val_loss 0.302 val_auc_score 0.939\n",
      "----End of step 0:01:05.045544\n",
      "train_loss 0.297 val_loss 0.327 val_auc_score 0.924\n",
      "----End of step 0:01:04.882544\n",
      "train_loss 0.286 val_loss 0.287 val_auc_score 0.938\n",
      "----End of step 0:01:05.958689\n",
      "train_loss 0.277 val_loss 0.274 val_auc_score 0.946\n",
      "----End of step 0:01:04.617556\n",
      "train_loss 0.264 val_loss 0.266 val_auc_score 0.948\n",
      "----End of step 0:01:06.232215\n",
      "train_loss 0.251 val_loss 0.268 val_auc_score 0.949\n",
      "----End of step 0:01:04.725647\n",
      "train_loss 0.242 val_loss 0.267 val_auc_score 0.953\n",
      "----End of step 0:01:04.495397\n",
      "train_loss 0.230 val_loss 0.249 val_auc_score 0.955\n",
      "----End of step 0:01:04.046620\n",
      "train_loss 0.221 val_loss 0.248 val_auc_score 0.957\n",
      "----End of step 0:01:03.786510\n",
      "train_loss 0.211 val_loss 0.245 val_auc_score 0.958\n",
      "----End of step 0:01:03.775228\n",
      "train_loss 0.204 val_loss 0.245 val_auc_score 0.958\n",
      "----End of step 0:01:04.174690\n",
      "train_loss 0.200 val_loss 0.246 val_auc_score 0.958\n",
      "----End of step 0:01:05.623886\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(5):\n",
    "    model = resnet18(block=depthwise_block, num_classes=1000).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/model_320_iter20_770.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                               loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                               dataset='rsna', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'rsna', 'resnet_full'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.25_full_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.428 val_loss 0.399 val_auc_score 0.888\n",
      "----End of step 0:01:03.892860\n",
      "train_loss 0.380 val_loss 0.523 val_auc_score 0.893\n",
      "----End of step 0:01:03.339095\n",
      "train_loss 0.363 val_loss 0.409 val_auc_score 0.910\n",
      "----End of step 0:01:03.646547\n",
      "train_loss 0.344 val_loss 0.382 val_auc_score 0.915\n",
      "----End of step 0:01:03.616040\n",
      "train_loss 0.333 val_loss 0.336 val_auc_score 0.924\n",
      "----End of step 0:01:02.905589\n",
      "train_loss 0.325 val_loss 0.339 val_auc_score 0.927\n",
      "----End of step 0:01:04.380192\n",
      "train_loss 0.316 val_loss 0.315 val_auc_score 0.931\n",
      "----End of step 0:01:03.081329\n",
      "train_loss 0.306 val_loss 0.313 val_auc_score 0.935\n",
      "----End of step 0:01:04.522483\n",
      "train_loss 0.297 val_loss 0.307 val_auc_score 0.936\n",
      "----End of step 0:01:06.598747\n",
      "train_loss 0.286 val_loss 0.301 val_auc_score 0.937\n",
      "----End of step 0:01:06.355851\n",
      "train_loss 0.278 val_loss 0.303 val_auc_score 0.939\n",
      "----End of step 0:01:04.623424\n",
      "train_loss 0.273 val_loss 0.290 val_auc_score 0.942\n",
      "----End of step 0:01:04.535492\n",
      "train_loss 0.267 val_loss 0.285 val_auc_score 0.944\n",
      "----End of step 0:01:04.573083\n",
      "train_loss 0.263 val_loss 0.281 val_auc_score 0.944\n",
      "----End of step 0:01:05.204168\n",
      "train_loss 0.260 val_loss 0.280 val_auc_score 0.944\n",
      "----End of step 0:01:05.927269\n",
      "train_loss 0.430 val_loss 0.471 val_auc_score 0.878\n",
      "----End of step 0:01:05.574721\n",
      "train_loss 0.384 val_loss 0.372 val_auc_score 0.900\n",
      "----End of step 0:01:06.186777\n",
      "train_loss 0.364 val_loss 0.371 val_auc_score 0.908\n",
      "----End of step 0:01:05.751212\n",
      "train_loss 0.349 val_loss 0.339 val_auc_score 0.916\n",
      "----End of step 0:01:06.141129\n",
      "train_loss 0.337 val_loss 0.331 val_auc_score 0.921\n",
      "----End of step 0:01:04.421913\n",
      "train_loss 0.324 val_loss 0.326 val_auc_score 0.923\n",
      "----End of step 0:01:04.757109\n",
      "train_loss 0.316 val_loss 0.307 val_auc_score 0.931\n",
      "----End of step 0:01:05.130428\n",
      "train_loss 0.307 val_loss 0.308 val_auc_score 0.934\n",
      "----End of step 0:01:07.395744\n",
      "train_loss 0.299 val_loss 0.308 val_auc_score 0.933\n",
      "----End of step 0:01:06.357132\n",
      "train_loss 0.290 val_loss 0.312 val_auc_score 0.936\n",
      "----End of step 0:01:05.292207\n",
      "train_loss 0.284 val_loss 0.306 val_auc_score 0.938\n",
      "----End of step 0:01:06.278381\n",
      "train_loss 0.273 val_loss 0.301 val_auc_score 0.942\n",
      "----End of step 0:01:05.280790\n",
      "train_loss 0.265 val_loss 0.293 val_auc_score 0.942\n",
      "----End of step 0:01:05.355629\n",
      "train_loss 0.261 val_loss 0.284 val_auc_score 0.944\n",
      "----End of step 0:01:05.407137\n",
      "train_loss 0.260 val_loss 0.287 val_auc_score 0.944\n",
      "----End of step 0:01:05.702156\n",
      "train_loss 0.429 val_loss 0.389 val_auc_score 0.891\n",
      "----End of step 0:01:05.151477\n",
      "train_loss 0.385 val_loss 0.392 val_auc_score 0.905\n",
      "----End of step 0:01:05.532751\n",
      "train_loss 0.364 val_loss 0.413 val_auc_score 0.911\n",
      "----End of step 0:01:04.853439\n",
      "train_loss 0.347 val_loss 0.357 val_auc_score 0.920\n",
      "----End of step 0:01:06.119712\n",
      "train_loss 0.337 val_loss 0.348 val_auc_score 0.921\n",
      "----End of step 0:01:05.256249\n",
      "train_loss 0.324 val_loss 0.327 val_auc_score 0.922\n",
      "----End of step 0:01:04.892139\n",
      "train_loss 0.317 val_loss 0.333 val_auc_score 0.928\n",
      "----End of step 0:01:04.152460\n",
      "train_loss 0.307 val_loss 0.315 val_auc_score 0.926\n",
      "----End of step 0:01:05.079341\n",
      "train_loss 0.300 val_loss 0.299 val_auc_score 0.937\n",
      "----End of step 0:01:04.972972\n",
      "train_loss 0.289 val_loss 0.298 val_auc_score 0.935\n",
      "----End of step 0:01:05.207384\n",
      "train_loss 0.282 val_loss 0.288 val_auc_score 0.939\n",
      "----End of step 0:01:04.696884\n",
      "train_loss 0.274 val_loss 0.287 val_auc_score 0.942\n",
      "----End of step 0:01:05.486899\n",
      "train_loss 0.267 val_loss 0.285 val_auc_score 0.943\n",
      "----End of step 0:01:05.284240\n",
      "train_loss 0.262 val_loss 0.290 val_auc_score 0.943\n",
      "----End of step 0:01:05.730739\n",
      "train_loss 0.258 val_loss 0.284 val_auc_score 0.944\n",
      "----End of step 0:01:06.549677\n",
      "train_loss 0.428 val_loss 0.402 val_auc_score 0.890\n",
      "----End of step 0:01:05.395161\n",
      "train_loss 0.386 val_loss 0.374 val_auc_score 0.905\n",
      "----End of step 0:01:05.356008\n",
      "train_loss 0.366 val_loss 0.348 val_auc_score 0.914\n",
      "----End of step 0:01:05.523166\n",
      "train_loss 0.346 val_loss 0.333 val_auc_score 0.924\n",
      "----End of step 0:01:05.657853\n",
      "train_loss 0.331 val_loss 0.353 val_auc_score 0.916\n",
      "----End of step 0:01:04.389359\n",
      "train_loss 0.323 val_loss 0.340 val_auc_score 0.927\n",
      "----End of step 0:01:05.217798\n",
      "train_loss 0.313 val_loss 0.324 val_auc_score 0.929\n",
      "----End of step 0:01:04.353354\n",
      "train_loss 0.303 val_loss 0.300 val_auc_score 0.937\n",
      "----End of step 0:01:04.242992\n",
      "train_loss 0.295 val_loss 0.306 val_auc_score 0.936\n",
      "----End of step 0:01:04.306700\n",
      "train_loss 0.288 val_loss 0.316 val_auc_score 0.936\n",
      "----End of step 0:01:04.578184\n",
      "train_loss 0.279 val_loss 0.284 val_auc_score 0.943\n",
      "----End of step 0:01:04.996620\n",
      "train_loss 0.271 val_loss 0.289 val_auc_score 0.943\n",
      "----End of step 0:01:05.077092\n",
      "train_loss 0.262 val_loss 0.290 val_auc_score 0.944\n",
      "----End of step 0:01:05.191760\n",
      "train_loss 0.260 val_loss 0.282 val_auc_score 0.945\n",
      "----End of step 0:01:04.841497\n",
      "train_loss 0.256 val_loss 0.281 val_auc_score 0.945\n",
      "----End of step 0:01:04.984408\n",
      "train_loss 0.427 val_loss 0.378 val_auc_score 0.895\n",
      "----End of step 0:01:04.132087\n",
      "train_loss 0.378 val_loss 0.361 val_auc_score 0.906\n",
      "----End of step 0:01:06.246365\n",
      "train_loss 0.359 val_loss 0.372 val_auc_score 0.904\n",
      "----End of step 0:01:06.460341\n",
      "train_loss 0.347 val_loss 0.355 val_auc_score 0.910\n",
      "----End of step 0:01:05.027048\n",
      "train_loss 0.337 val_loss 0.325 val_auc_score 0.923\n",
      "----End of step 0:01:04.018927\n",
      "train_loss 0.326 val_loss 0.370 val_auc_score 0.922\n",
      "----End of step 0:01:04.701730\n",
      "train_loss 0.315 val_loss 0.372 val_auc_score 0.926\n",
      "----End of step 0:01:05.128153\n",
      "train_loss 0.306 val_loss 0.316 val_auc_score 0.929\n",
      "----End of step 0:01:04.815711\n",
      "train_loss 0.296 val_loss 0.305 val_auc_score 0.935\n",
      "----End of step 0:01:05.191234\n",
      "train_loss 0.289 val_loss 0.293 val_auc_score 0.938\n",
      "----End of step 0:01:04.926430\n",
      "train_loss 0.279 val_loss 0.285 val_auc_score 0.942\n",
      "----End of step 0:01:05.360915\n",
      "train_loss 0.274 val_loss 0.292 val_auc_score 0.943\n",
      "----End of step 0:01:05.344608\n",
      "train_loss 0.266 val_loss 0.282 val_auc_score 0.944\n",
      "----End of step 0:01:05.086067\n",
      "train_loss 0.259 val_loss 0.281 val_auc_score 0.945\n",
      "----End of step 0:01:05.023478\n",
      "train_loss 0.257 val_loss 0.279 val_auc_score 0.945\n",
      "----End of step 0:01:07.933253\n",
      "train_loss 0.429 val_loss 0.406 val_auc_score 0.883\n",
      "----End of step 0:01:06.042920\n",
      "train_loss 0.384 val_loss 0.420 val_auc_score 0.891\n",
      "----End of step 0:01:05.264234\n",
      "train_loss 0.364 val_loss 0.388 val_auc_score 0.903\n",
      "----End of step 0:01:05.120546\n",
      "train_loss 0.350 val_loss 0.348 val_auc_score 0.920\n",
      "----End of step 0:01:08.505695\n",
      "train_loss 0.337 val_loss 0.325 val_auc_score 0.922\n",
      "----End of step 0:01:05.015845\n",
      "train_loss 0.326 val_loss 0.318 val_auc_score 0.928\n",
      "----End of step 0:01:04.747763\n",
      "train_loss 0.314 val_loss 0.321 val_auc_score 0.931\n",
      "----End of step 0:01:04.242363\n",
      "train_loss 0.307 val_loss 0.310 val_auc_score 0.932\n",
      "----End of step 0:01:04.691317\n",
      "train_loss 0.297 val_loss 0.300 val_auc_score 0.937\n",
      "----End of step 0:01:05.274189\n",
      "train_loss 0.288 val_loss 0.298 val_auc_score 0.938\n",
      "----End of step 0:01:05.560892\n",
      "train_loss 0.280 val_loss 0.288 val_auc_score 0.940\n",
      "----End of step 0:01:08.816049\n",
      "train_loss 0.273 val_loss 0.291 val_auc_score 0.942\n",
      "----End of step 0:01:09.642836\n",
      "train_loss 0.267 val_loss 0.290 val_auc_score 0.943\n",
      "----End of step 0:01:09.889417\n",
      "train_loss 0.263 val_loss 0.282 val_auc_score 0.943\n",
      "----End of step 0:01:09.795124\n",
      "train_loss 0.262 val_loss 0.284 val_auc_score 0.944\n",
      "----End of step 0:01:06.113258\n",
      "train_loss 0.429 val_loss 0.387 val_auc_score 0.889\n",
      "----End of step 0:01:05.024169\n",
      "train_loss 0.385 val_loss 0.359 val_auc_score 0.905\n",
      "----End of step 0:01:05.098973\n",
      "train_loss 0.363 val_loss 0.372 val_auc_score 0.911\n",
      "----End of step 0:01:04.955034\n",
      "train_loss 0.347 val_loss 0.352 val_auc_score 0.917\n",
      "----End of step 0:01:04.961243\n",
      "train_loss 0.336 val_loss 0.332 val_auc_score 0.923\n",
      "----End of step 0:01:04.873157\n",
      "train_loss 0.324 val_loss 0.312 val_auc_score 0.927\n",
      "----End of step 0:01:04.370837\n",
      "train_loss 0.313 val_loss 0.310 val_auc_score 0.930\n",
      "----End of step 0:01:04.223727\n",
      "train_loss 0.304 val_loss 0.303 val_auc_score 0.932\n",
      "----End of step 0:01:06.764398\n",
      "train_loss 0.294 val_loss 0.304 val_auc_score 0.935\n",
      "----End of step 0:01:05.796085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.284 val_loss 0.295 val_auc_score 0.938\n",
      "----End of step 0:01:05.991761\n",
      "train_loss 0.278 val_loss 0.294 val_auc_score 0.941\n",
      "----End of step 0:01:04.141787\n",
      "train_loss 0.271 val_loss 0.284 val_auc_score 0.941\n",
      "----End of step 0:01:04.681192\n",
      "train_loss 0.264 val_loss 0.282 val_auc_score 0.943\n",
      "----End of step 0:01:03.849362\n",
      "train_loss 0.261 val_loss 0.284 val_auc_score 0.944\n",
      "----End of step 0:01:04.940434\n",
      "train_loss 0.258 val_loss 0.283 val_auc_score 0.944\n",
      "----End of step 0:01:05.223956\n",
      "train_loss 0.430 val_loss 0.402 val_auc_score 0.891\n",
      "----End of step 0:01:05.655339\n",
      "train_loss 0.385 val_loss 0.369 val_auc_score 0.906\n",
      "----End of step 0:01:04.023662\n",
      "train_loss 0.364 val_loss 0.358 val_auc_score 0.905\n",
      "----End of step 0:01:04.010139\n",
      "train_loss 0.348 val_loss 0.356 val_auc_score 0.906\n",
      "----End of step 0:01:04.912430\n",
      "train_loss 0.333 val_loss 0.336 val_auc_score 0.922\n",
      "----End of step 0:01:04.849374\n",
      "train_loss 0.324 val_loss 0.376 val_auc_score 0.919\n",
      "----End of step 0:01:05.472610\n",
      "train_loss 0.313 val_loss 0.311 val_auc_score 0.932\n",
      "----End of step 0:01:05.327369\n",
      "train_loss 0.306 val_loss 0.300 val_auc_score 0.934\n",
      "----End of step 0:01:05.328342\n",
      "train_loss 0.295 val_loss 0.305 val_auc_score 0.936\n",
      "----End of step 0:01:03.592542\n",
      "train_loss 0.288 val_loss 0.293 val_auc_score 0.938\n",
      "----End of step 0:01:04.705852\n",
      "train_loss 0.280 val_loss 0.284 val_auc_score 0.941\n",
      "----End of step 0:01:08.491907\n",
      "train_loss 0.273 val_loss 0.292 val_auc_score 0.942\n",
      "----End of step 0:01:05.410072\n",
      "train_loss 0.264 val_loss 0.285 val_auc_score 0.943\n",
      "----End of step 0:01:06.621760\n",
      "train_loss 0.262 val_loss 0.285 val_auc_score 0.943\n",
      "----End of step 0:01:05.535936\n",
      "train_loss 0.257 val_loss 0.281 val_auc_score 0.944\n",
      "----End of step 0:01:06.153882\n",
      "train_loss 0.429 val_loss 0.419 val_auc_score 0.885\n",
      "----End of step 0:01:08.409593\n",
      "train_loss 0.385 val_loss 0.406 val_auc_score 0.877\n",
      "----End of step 0:01:04.951059\n",
      "train_loss 0.365 val_loss 0.361 val_auc_score 0.917\n",
      "----End of step 0:01:04.495268\n",
      "train_loss 0.348 val_loss 0.350 val_auc_score 0.917\n",
      "----End of step 0:01:07.188523\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2a0d69106d74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n\u001b[1;32m      7\u001b[0m                                        \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                                        dataset='rsna', binary=True, max_lr=0.01, epochs=15)\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rsna'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet_0_25_full_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Medical_Images/training.py\u001b[0m in \u001b[0;36mtrain_triangular_policy\u001b[0;34m(model, optimizer, train_dl, valid_dl, valid_dataset, loss_fn, dataset, binary, max_lr, epochs)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.25).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_25_1_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='rsna', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'rsna', 'resnet_0_25_full_depth'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    d = depths[4]\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.5, \n",
    "                     inverted_residual_setting1=d[0], \n",
    "                     inverted_residual_setting2=d[1]).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_4_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='rsna', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'rsna', 'resnet_0_5_4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_full_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.5).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_1_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='rsna', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'rsna', 'resnet_0_5_full_depth'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_75_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    d = depths[4]\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.75, \n",
    "                     inverted_residual_setting1=d[0], \n",
    "                     inverted_residual_setting2=d[1]).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_4_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='rsna', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'rsna', 'resnet_0_75_4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['score', 'time', 'dataset', 'model']\n",
    "df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"rsna_resnet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
