{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, valid_dataset = mura_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 250, 200]), torch.Size([32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basicblock(in_, \n",
    "               out_, \n",
    "               kernel_size=3, \n",
    "               stride=1, \n",
    "               groups=1):\n",
    "\n",
    "    \n",
    "    padding = (kernel_size - 1) // 2\n",
    "    block = nn.Sequential(nn.Conv2d(in_, out_, kernel_size, stride, padding, groups=groups, bias=False),\n",
    "                          nn.BatchNorm2d(out_),\n",
    "                          nn.ReLU6(inplace=True))\n",
    "    \n",
    "    return block\n",
    "\n",
    "class InvertedResblock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_, out_, kernel_size=3, stride=1, expand_ratio=1):\n",
    "        super(InvertedResblock, self).__init__()\n",
    "        \n",
    "        self.stride = stride\n",
    "        hidden_dim = int(round(in_ * expand_ratio))\n",
    "        blocks = []\n",
    "        self.use_res_connect = self.stride == 1 and in_ == out_\n",
    "        \n",
    "        if expand_ratio != 1:\n",
    "            blocks.append(basicblock(in_, hidden_dim, kernel_size=1))\n",
    "\n",
    "        blocks.append(basicblock(hidden_dim, hidden_dim, kernel_size=kernel_size, stride=stride, groups=hidden_dim))\n",
    "        blocks.append(nn.Conv2d(hidden_dim, out_, kernel_size=1, stride=1, bias=False))\n",
    "        blocks.append(nn.BatchNorm2d(out_))\n",
    "\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.blocks(x)\n",
    "        else:\n",
    "            return self.blocks(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=1):\n",
    "        super(Net, self).__init__()\n",
    "        self.features1 = nn.Sequential(basicblock(3, 32, 3, 2, 1),\n",
    "                                       InvertedResblock(32, 16, 3, 1, 1), \n",
    "                                       InvertedResblock(16, 24, 3, 2, 6),\n",
    "                                       InvertedResblock(24, 24, 3, 1, 6),\n",
    "                                       InvertedResblock(24, 32, 3, 2, 6),\n",
    "                                       InvertedResblock(32, 32, 3, 1, 6),\n",
    "                                       InvertedResblock(32, 32, 3, 1, 6), \n",
    "                                       InvertedResblock(32, 64, 3, 2, 6),\n",
    "                                       InvertedResblock(64, 64, 3, 1, 6),\n",
    "                                       InvertedResblock(64, 64, 3, 1, 6),\n",
    "                                       InvertedResblock(64, 64, 3, 1, 6),\n",
    "                                       InvertedResblock(64, 96, 3, 1, 6),\n",
    "                                       InvertedResblock(96, 96, 3, 1, 6),\n",
    "                                       InvertedResblock(96, 96, 3, 1, 6),\n",
    "                                       InvertedResblock(96, 160, 3, 2, 6))\n",
    "    \n",
    "        self.features2 = nn.Sequential(InvertedResblock(160, 160, 3, 1, 6),\n",
    "                                       InvertedResblock(160, 160, 3, 1, 6),\n",
    "                                       InvertedResblock(160, 320, 3, 1, 6),\n",
    "                                       basicblock(320, 1280, 1))\n",
    "        self.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(1280, 1000))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        x = self.features2(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3504872"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, '/home/rimmanni/imagenet/mobilenet_320_iter20_revised.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net2(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(Net2, self).__init__()\n",
    "        self.features1 = model.features1\n",
    "        self.features2 = model.features2\n",
    "        self.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(1280, 1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features1(x)\n",
    "        x = self.features2(x)\n",
    "        x = x.mean(3).mean(2)\n",
    "        x1 = self.classifier(x).view(-1)\n",
    "\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Net2(model).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.533 val_loss 0.507 val_auc_score 0.848\n",
      "----End of step 0:01:27.173549\n",
      "train_loss 0.497 val_loss 0.517 val_auc_score 0.835\n",
      "----End of step 0:01:28.861324\n",
      "train_loss 0.493 val_loss 0.523 val_auc_score 0.824\n",
      "----End of step 0:01:27.720164\n",
      "train_loss 0.482 val_loss 0.484 val_auc_score 0.866\n",
      "----End of step 0:01:29.239619\n",
      "train_loss 0.476 val_loss 0.535 val_auc_score 0.836\n",
      "----End of step 0:01:30.012804\n",
      "train_loss 0.468 val_loss 0.500 val_auc_score 0.847\n",
      "----End of step 0:01:29.437794\n",
      "train_loss 0.458 val_loss 0.528 val_auc_score 0.850\n",
      "----End of step 0:01:29.486535\n",
      "train_loss 0.445 val_loss 0.478 val_auc_score 0.862\n",
      "----End of step 0:01:28.974766\n",
      "train_loss 0.432 val_loss 0.477 val_auc_score 0.878\n",
      "----End of step 0:01:30.688439\n",
      "train_loss 0.419 val_loss 0.449 val_auc_score 0.880\n",
      "----End of step 0:01:31.697574\n",
      "train_loss 0.402 val_loss 0.446 val_auc_score 0.891\n",
      "----End of step 0:01:30.585544\n",
      "train_loss 0.386 val_loss 0.457 val_auc_score 0.891\n",
      "----End of step 0:01:32.836341\n",
      "train_loss 0.370 val_loss 0.449 val_auc_score 0.893\n",
      "----End of step 0:01:32.260087\n",
      "train_loss 0.359 val_loss 0.450 val_auc_score 0.893\n",
      "----End of step 0:01:33.010131\n",
      "train_loss 0.357 val_loss 0.448 val_auc_score 0.895\n",
      "----End of step 0:01:32.595938\n",
      "train_loss 0.383 val_loss 0.461 val_auc_score 0.889\n",
      "----End of step 0:01:31.504227\n",
      "train_loss 0.398 val_loss 0.468 val_auc_score 0.873\n",
      "----End of step 0:01:32.592131\n",
      "train_loss 0.423 val_loss 0.486 val_auc_score 0.854\n",
      "----End of step 0:01:32.756959\n",
      "train_loss 0.431 val_loss 0.493 val_auc_score 0.880\n",
      "----End of step 0:01:32.398107\n",
      "train_loss 0.431 val_loss 0.497 val_auc_score 0.877\n",
      "----End of step 0:01:31.174026\n",
      "train_loss 0.427 val_loss 0.519 val_auc_score 0.879\n",
      "----End of step 0:01:30.744180\n",
      "train_loss 0.422 val_loss 0.467 val_auc_score 0.891\n",
      "----End of step 0:01:30.514269\n",
      "train_loss 0.409 val_loss 0.451 val_auc_score 0.885\n",
      "----End of step 0:01:30.500900\n",
      "train_loss 0.397 val_loss 0.433 val_auc_score 0.895\n",
      "----End of step 0:01:31.530130\n",
      "train_loss 0.383 val_loss 0.451 val_auc_score 0.895\n",
      "----End of step 0:01:30.417763\n",
      "train_loss 0.366 val_loss 0.440 val_auc_score 0.893\n",
      "----End of step 0:01:32.379881\n",
      "train_loss 0.349 val_loss 0.453 val_auc_score 0.894\n",
      "----End of step 0:01:32.708001\n",
      "train_loss 0.338 val_loss 0.461 val_auc_score 0.895\n",
      "----End of step 0:01:31.729779\n",
      "train_loss 0.326 val_loss 0.451 val_auc_score 0.894\n",
      "----End of step 0:01:32.412735\n",
      "train_loss 0.321 val_loss 0.466 val_auc_score 0.893\n",
      "----End of step 0:01:33.643105\n",
      "train_loss 0.357 val_loss 0.468 val_auc_score 0.890\n",
      "----End of step 0:01:32.773895\n",
      "train_loss 0.366 val_loss 0.516 val_auc_score 0.872\n",
      "----End of step 0:01:37.132176\n",
      "train_loss 0.397 val_loss 0.462 val_auc_score 0.877\n",
      "----End of step 0:01:35.949613\n",
      "train_loss 0.405 val_loss 0.470 val_auc_score 0.875\n",
      "----End of step 0:01:32.945564\n",
      "train_loss 0.406 val_loss 0.491 val_auc_score 0.874\n",
      "----End of step 0:01:36.281350\n",
      "train_loss 0.405 val_loss 0.488 val_auc_score 0.873\n",
      "----End of step 0:01:34.265022\n",
      "train_loss 0.395 val_loss 0.479 val_auc_score 0.874\n",
      "----End of step 0:01:33.854139\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(5):\n",
    "    model2 = Net2(model).cuda()\n",
    "    optimizer = create_optimizer(model2, 0.01)\n",
    "    score, t = train_triangular_policy(model2, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                               loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                               dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'mobilenet_full'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../architectures.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.25_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = MobileNet(num_classes=1000, width_mult=0.25, depth_mult=1.0).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/mobilenet_0_25_1_iter20.pth')\n",
    "    model.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(1280, 1)).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'mobilenet_0_25_1'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_0_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = MobileNet(num_classes=1000, width_mult=0.5, depth_mult=0.5).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/mobilenet_0_5_0_5_iter20.pth')\n",
    "    model.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(1280, 1)).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'mobilenet_0_5_0_5'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_75_0_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = MobileNet(num_classes=1000, width_mult=0.75, depth_mult=0.3).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/mobilenet_0_75_0_3_iter20.pth')\n",
    "    model.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(1280, 1)).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'mobilenet_0_75_0_3'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1_0_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = MobileNet(num_classes=1000, width_mult=1.0, depth_mult=0.2).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/mobilenet_1_0_2_iter20.pth')\n",
    "    model.classifier = nn.Sequential(nn.Dropout(p=0.2), nn.Linear(1280, 1)).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'mobilenet_1_0_2'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['score', 'time', 'dataset', 'model']\n",
    "df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mura_mobilenet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
