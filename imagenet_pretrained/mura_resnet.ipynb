{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.set_device(1)\n",
    "print(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../architectures.py\n",
    "%run ../prepare_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader, valid_dataset = mura_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 3, 250, 200]), torch.Size([32]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = [[[[64, 2], [128, 2]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 2], [128, 2]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 1], [512, 1]]],\n",
    "          [[[64, 2], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 2], [512, 1]]],\n",
    "          [[[64, 1], [128, 1]], [[256, 1], [512, 1]]],\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.527 val_loss 0.565 val_auc_score 0.837\n",
      "----End of step 0:01:04.257557\n",
      "train_loss 0.509 val_loss 0.548 val_auc_score 0.816\n",
      "----End of step 0:01:01.997516\n",
      "train_loss 0.516 val_loss 0.777 val_auc_score 0.799\n",
      "----End of step 0:01:03.720028\n",
      "train_loss 0.508 val_loss 0.606 val_auc_score 0.816\n",
      "----End of step 0:01:02.977707\n",
      "train_loss 0.503 val_loss 0.537 val_auc_score 0.836\n",
      "----End of step 0:01:03.334574\n",
      "train_loss 0.490 val_loss 0.513 val_auc_score 0.849\n",
      "----End of step 0:01:04.092012\n",
      "train_loss 0.478 val_loss 0.529 val_auc_score 0.830\n",
      "----End of step 0:01:04.294941\n",
      "train_loss 0.464 val_loss 0.506 val_auc_score 0.849\n",
      "----End of step 0:01:04.213025\n",
      "train_loss 0.454 val_loss 0.464 val_auc_score 0.873\n",
      "----End of step 0:01:03.944689\n",
      "train_loss 0.436 val_loss 0.475 val_auc_score 0.873\n",
      "----End of step 0:01:03.647843\n",
      "train_loss 0.422 val_loss 0.439 val_auc_score 0.886\n",
      "----End of step 0:01:03.844681\n",
      "train_loss 0.408 val_loss 0.446 val_auc_score 0.885\n",
      "----End of step 0:01:03.332255\n",
      "train_loss 0.394 val_loss 0.435 val_auc_score 0.891\n",
      "----End of step 0:01:03.479333\n",
      "train_loss 0.383 val_loss 0.439 val_auc_score 0.892\n",
      "----End of step 0:01:03.314083\n",
      "train_loss 0.379 val_loss 0.443 val_auc_score 0.890\n",
      "----End of step 0:01:03.678103\n",
      "train_loss 0.528 val_loss 0.595 val_auc_score 0.818\n",
      "----End of step 0:01:03.116599\n",
      "train_loss 0.510 val_loss 0.597 val_auc_score 0.759\n",
      "----End of step 0:01:02.960811\n",
      "train_loss 0.516 val_loss 0.590 val_auc_score 0.837\n",
      "----End of step 0:01:03.164637\n",
      "train_loss 0.511 val_loss 0.535 val_auc_score 0.834\n",
      "----End of step 0:01:04.643116\n",
      "train_loss 0.504 val_loss 0.514 val_auc_score 0.850\n",
      "----End of step 0:01:03.973031\n",
      "train_loss 0.492 val_loss 0.738 val_auc_score 0.786\n",
      "----End of step 0:01:04.101736\n",
      "train_loss 0.480 val_loss 0.530 val_auc_score 0.836\n",
      "----End of step 0:01:04.281709\n",
      "train_loss 0.467 val_loss 0.505 val_auc_score 0.847\n",
      "----End of step 0:01:03.787928\n",
      "train_loss 0.454 val_loss 0.475 val_auc_score 0.865\n",
      "----End of step 0:01:04.120477\n",
      "train_loss 0.439 val_loss 0.517 val_auc_score 0.872\n",
      "----End of step 0:01:03.761738\n",
      "train_loss 0.424 val_loss 0.455 val_auc_score 0.878\n",
      "----End of step 0:01:04.105747\n",
      "train_loss 0.407 val_loss 0.447 val_auc_score 0.882\n",
      "----End of step 0:01:04.307421\n",
      "train_loss 0.395 val_loss 0.445 val_auc_score 0.883\n",
      "----End of step 0:01:04.190318\n",
      "train_loss 0.384 val_loss 0.445 val_auc_score 0.885\n",
      "----End of step 0:01:04.382998\n",
      "train_loss 0.377 val_loss 0.448 val_auc_score 0.886\n",
      "----End of step 0:01:04.128259\n",
      "train_loss 0.525 val_loss 0.546 val_auc_score 0.823\n",
      "----End of step 0:01:04.111925\n",
      "train_loss 0.512 val_loss 0.577 val_auc_score 0.776\n",
      "----End of step 0:01:03.222208\n",
      "train_loss 0.514 val_loss 0.665 val_auc_score 0.805\n",
      "----End of step 0:01:04.062661\n",
      "train_loss 0.512 val_loss 0.527 val_auc_score 0.833\n",
      "----End of step 0:01:03.133901\n",
      "train_loss 0.500 val_loss 0.549 val_auc_score 0.837\n",
      "----End of step 0:01:03.923518\n",
      "train_loss 0.491 val_loss 0.644 val_auc_score 0.835\n",
      "----End of step 0:01:03.959092\n",
      "train_loss 0.477 val_loss 0.491 val_auc_score 0.865\n",
      "----End of step 0:01:03.653967\n",
      "train_loss 0.465 val_loss 0.504 val_auc_score 0.849\n",
      "----End of step 0:01:03.960131\n",
      "train_loss 0.453 val_loss 0.460 val_auc_score 0.878\n",
      "----End of step 0:01:04.356746\n",
      "train_loss 0.435 val_loss 0.517 val_auc_score 0.866\n",
      "----End of step 0:01:03.571367\n",
      "train_loss 0.424 val_loss 0.439 val_auc_score 0.884\n",
      "----End of step 0:01:03.531368\n",
      "train_loss 0.407 val_loss 0.450 val_auc_score 0.880\n",
      "----End of step 0:01:04.423895\n",
      "train_loss 0.394 val_loss 0.444 val_auc_score 0.885\n",
      "----End of step 0:01:04.241653\n",
      "train_loss 0.384 val_loss 0.444 val_auc_score 0.888\n",
      "----End of step 0:01:04.025865\n",
      "train_loss 0.376 val_loss 0.446 val_auc_score 0.890\n",
      "----End of step 0:01:04.237431\n",
      "train_loss 0.525 val_loss 0.594 val_auc_score 0.841\n",
      "----End of step 0:01:04.314657\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-8e5891e946f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n\u001b[1;32m      8\u001b[0m                                                \u001b[0mloss_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                                                dataset='mura', binary=True, max_lr=0.01, epochs=15)\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mura'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'resnet_full'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Medical_Images/training.py\u001b[0m in \u001b[0;36mtrain_triangular_policy\u001b[0;34m(model, optimizer, train_dl, valid_dl, valid_dataset, loss_fn, dataset, binary, max_lr, epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0midx\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    101\u001b[0m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m                     \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'eps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/model_320_iter20_vartion4.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                               loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                               dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_full'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8885461365847623"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([i[0] for i in data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.556 val_loss 0.723 val_auc_score 0.781\n",
      "----End of step 0:00:47.508293\n",
      "train_loss 0.518 val_loss 0.757 val_auc_score 0.799\n",
      "----End of step 0:00:49.206025\n",
      "train_loss 0.513 val_loss 0.544 val_auc_score 0.826\n",
      "----End of step 0:00:47.856143\n",
      "train_loss 0.504 val_loss 0.538 val_auc_score 0.820\n",
      "----End of step 0:00:48.557878\n",
      "train_loss 0.492 val_loss 0.547 val_auc_score 0.835\n",
      "----End of step 0:00:48.095076\n",
      "train_loss 0.486 val_loss 0.500 val_auc_score 0.850\n",
      "----End of step 0:00:48.604373\n",
      "train_loss 0.475 val_loss 0.525 val_auc_score 0.855\n",
      "----End of step 0:00:48.039251\n",
      "train_loss 0.466 val_loss 0.493 val_auc_score 0.855\n",
      "----End of step 0:00:48.142240\n",
      "train_loss 0.453 val_loss 0.509 val_auc_score 0.862\n",
      "----End of step 0:00:47.293892\n",
      "train_loss 0.438 val_loss 0.488 val_auc_score 0.860\n",
      "----End of step 0:00:47.838071\n",
      "train_loss 0.424 val_loss 0.480 val_auc_score 0.868\n",
      "----End of step 0:00:48.186815\n",
      "train_loss 0.413 val_loss 0.467 val_auc_score 0.872\n",
      "----End of step 0:00:48.452339\n",
      "train_loss 0.398 val_loss 0.469 val_auc_score 0.876\n",
      "----End of step 0:00:47.776298\n",
      "train_loss 0.387 val_loss 0.468 val_auc_score 0.878\n",
      "----End of step 0:00:47.599770\n",
      "train_loss 0.382 val_loss 0.471 val_auc_score 0.880\n",
      "----End of step 0:00:47.289172\n",
      "train_loss 0.557 val_loss 0.644 val_auc_score 0.797\n",
      "----End of step 0:00:47.922248\n",
      "train_loss 0.523 val_loss 0.575 val_auc_score 0.826\n",
      "----End of step 0:00:46.705541\n",
      "train_loss 0.517 val_loss 0.530 val_auc_score 0.817\n",
      "----End of step 0:00:47.286837\n",
      "train_loss 0.505 val_loss 0.604 val_auc_score 0.828\n",
      "----End of step 0:00:46.776896\n",
      "train_loss 0.496 val_loss 0.522 val_auc_score 0.822\n",
      "----End of step 0:00:47.275216\n",
      "train_loss 0.486 val_loss 0.550 val_auc_score 0.814\n",
      "----End of step 0:00:48.068709\n",
      "train_loss 0.475 val_loss 0.715 val_auc_score 0.830\n",
      "----End of step 0:00:47.427346\n",
      "train_loss 0.466 val_loss 0.544 val_auc_score 0.841\n",
      "----End of step 0:00:48.053986\n",
      "train_loss 0.455 val_loss 0.486 val_auc_score 0.857\n",
      "----End of step 0:00:47.095544\n",
      "train_loss 0.441 val_loss 0.505 val_auc_score 0.864\n",
      "----End of step 0:00:47.051420\n",
      "train_loss 0.426 val_loss 0.505 val_auc_score 0.861\n",
      "----End of step 0:00:47.022025\n",
      "train_loss 0.412 val_loss 0.485 val_auc_score 0.871\n",
      "----End of step 0:00:48.486203\n",
      "train_loss 0.401 val_loss 0.467 val_auc_score 0.873\n",
      "----End of step 0:00:47.282702\n",
      "train_loss 0.390 val_loss 0.471 val_auc_score 0.876\n",
      "----End of step 0:00:47.841484\n",
      "train_loss 0.386 val_loss 0.470 val_auc_score 0.875\n",
      "----End of step 0:00:47.231391\n",
      "train_loss 0.555 val_loss 0.549 val_auc_score 0.821\n",
      "----End of step 0:00:48.335602\n",
      "train_loss 0.522 val_loss 0.542 val_auc_score 0.813\n",
      "----End of step 0:00:47.474093\n",
      "train_loss 0.515 val_loss 0.585 val_auc_score 0.808\n",
      "----End of step 0:00:49.468604\n",
      "train_loss 0.506 val_loss 0.591 val_auc_score 0.827\n",
      "----End of step 0:00:48.555640\n",
      "train_loss 0.495 val_loss 0.510 val_auc_score 0.856\n",
      "----End of step 0:00:48.591107\n",
      "train_loss 0.484 val_loss 0.500 val_auc_score 0.842\n",
      "----End of step 0:00:48.876032\n",
      "train_loss 0.475 val_loss 0.520 val_auc_score 0.855\n",
      "----End of step 0:00:48.980538\n",
      "train_loss 0.464 val_loss 0.625 val_auc_score 0.845\n",
      "----End of step 0:00:48.168876\n",
      "train_loss 0.450 val_loss 0.576 val_auc_score 0.849\n",
      "----End of step 0:00:48.231955\n",
      "train_loss 0.440 val_loss 0.471 val_auc_score 0.871\n",
      "----End of step 0:00:48.916265\n",
      "train_loss 0.424 val_loss 0.485 val_auc_score 0.869\n",
      "----End of step 0:00:48.952905\n",
      "train_loss 0.410 val_loss 0.480 val_auc_score 0.873\n",
      "----End of step 0:00:49.065242\n",
      "train_loss 0.399 val_loss 0.470 val_auc_score 0.878\n",
      "----End of step 0:00:49.576845\n",
      "train_loss 0.388 val_loss 0.471 val_auc_score 0.880\n",
      "----End of step 0:00:48.045653\n",
      "train_loss 0.381 val_loss 0.473 val_auc_score 0.879\n",
      "----End of step 0:00:48.569498\n",
      "train_loss 0.556 val_loss 0.560 val_auc_score 0.815\n",
      "----End of step 0:00:47.741794\n",
      "train_loss 0.521 val_loss 0.531 val_auc_score 0.819\n",
      "----End of step 0:00:47.897224\n",
      "train_loss 0.514 val_loss 0.523 val_auc_score 0.834\n",
      "----End of step 0:00:48.599800\n",
      "train_loss 0.505 val_loss 0.569 val_auc_score 0.803\n",
      "----End of step 0:00:49.041326\n",
      "train_loss 0.496 val_loss 0.499 val_auc_score 0.850\n",
      "----End of step 0:00:49.480351\n",
      "train_loss 0.484 val_loss 0.527 val_auc_score 0.853\n",
      "----End of step 0:00:49.196902\n",
      "train_loss 0.475 val_loss 0.534 val_auc_score 0.833\n",
      "----End of step 0:00:49.626896\n",
      "train_loss 0.464 val_loss 0.483 val_auc_score 0.870\n",
      "----End of step 0:00:47.956600\n",
      "train_loss 0.453 val_loss 0.478 val_auc_score 0.866\n",
      "----End of step 0:00:48.545584\n",
      "train_loss 0.438 val_loss 0.493 val_auc_score 0.872\n",
      "----End of step 0:00:49.494823\n",
      "train_loss 0.426 val_loss 0.475 val_auc_score 0.868\n",
      "----End of step 0:00:49.246719\n",
      "train_loss 0.410 val_loss 0.491 val_auc_score 0.870\n",
      "----End of step 0:00:48.709462\n",
      "train_loss 0.397 val_loss 0.467 val_auc_score 0.875\n",
      "----End of step 0:00:49.393933\n",
      "train_loss 0.387 val_loss 0.461 val_auc_score 0.878\n",
      "----End of step 0:00:49.203803\n",
      "train_loss 0.380 val_loss 0.468 val_auc_score 0.875\n",
      "----End of step 0:00:48.721734\n",
      "train_loss 0.558 val_loss 0.552 val_auc_score 0.814\n",
      "----End of step 0:00:48.524640\n",
      "train_loss 0.521 val_loss 0.549 val_auc_score 0.816\n",
      "----End of step 0:00:48.258970\n",
      "train_loss 0.513 val_loss 0.556 val_auc_score 0.808\n",
      "----End of step 0:00:49.197130\n",
      "train_loss 0.504 val_loss 0.532 val_auc_score 0.832\n",
      "----End of step 0:00:48.813390\n",
      "train_loss 0.494 val_loss 0.568 val_auc_score 0.841\n",
      "----End of step 0:00:48.419317\n",
      "train_loss 0.484 val_loss 0.530 val_auc_score 0.837\n",
      "----End of step 0:00:48.891651\n",
      "train_loss 0.474 val_loss 0.507 val_auc_score 0.852\n",
      "----End of step 0:00:48.501772\n",
      "train_loss 0.465 val_loss 0.534 val_auc_score 0.851\n",
      "----End of step 0:00:48.979830\n",
      "train_loss 0.451 val_loss 0.480 val_auc_score 0.861\n",
      "----End of step 0:00:48.278273\n",
      "train_loss 0.439 val_loss 0.471 val_auc_score 0.867\n",
      "----End of step 0:00:49.220837\n",
      "train_loss 0.425 val_loss 0.469 val_auc_score 0.871\n",
      "----End of step 0:00:48.824912\n",
      "train_loss 0.410 val_loss 0.475 val_auc_score 0.880\n",
      "----End of step 0:00:48.369960\n",
      "train_loss 0.399 val_loss 0.479 val_auc_score 0.876\n",
      "----End of step 0:00:47.620684\n",
      "train_loss 0.388 val_loss 0.467 val_auc_score 0.877\n",
      "----End of step 0:00:49.501300\n",
      "train_loss 0.381 val_loss 0.474 val_auc_score 0.878\n",
      "----End of step 0:00:49.476092\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for i in range(5):\n",
    "    model = resnet18(block=depthwise_block, num_classes=1000).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/model_320_iter20_770.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                               loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                               dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_full'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.25_full_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.603 val_loss 0.645 val_auc_score 0.763\n",
      "----End of step 0:00:49.965903\n",
      "train_loss 0.563 val_loss 0.635 val_auc_score 0.804\n",
      "----End of step 0:00:49.741397\n",
      "train_loss 0.546 val_loss 0.572 val_auc_score 0.790\n",
      "----End of step 0:00:51.008879\n",
      "train_loss 0.533 val_loss 0.582 val_auc_score 0.793\n",
      "----End of step 0:00:50.746812\n",
      "train_loss 0.523 val_loss 0.525 val_auc_score 0.831\n",
      "----End of step 0:00:49.680609\n",
      "train_loss 0.515 val_loss 0.563 val_auc_score 0.826\n",
      "----End of step 0:00:50.952001\n",
      "train_loss 0.503 val_loss 0.544 val_auc_score 0.814\n",
      "----End of step 0:00:50.068861\n",
      "train_loss 0.496 val_loss 0.634 val_auc_score 0.836\n",
      "----End of step 0:00:50.314817\n",
      "train_loss 0.487 val_loss 0.500 val_auc_score 0.851\n",
      "----End of step 0:00:50.709722\n",
      "train_loss 0.478 val_loss 0.537 val_auc_score 0.854\n",
      "----End of step 0:00:49.146259\n",
      "train_loss 0.468 val_loss 0.499 val_auc_score 0.856\n",
      "----End of step 0:00:49.997019\n",
      "train_loss 0.460 val_loss 0.500 val_auc_score 0.864\n",
      "----End of step 0:00:50.501022\n",
      "train_loss 0.452 val_loss 0.501 val_auc_score 0.859\n",
      "----End of step 0:00:50.004499\n",
      "train_loss 0.448 val_loss 0.494 val_auc_score 0.863\n",
      "----End of step 0:00:50.532253\n",
      "train_loss 0.442 val_loss 0.494 val_auc_score 0.865\n",
      "----End of step 0:00:50.151141\n",
      "train_loss 0.607 val_loss 0.632 val_auc_score 0.786\n",
      "----End of step 0:00:48.933404\n",
      "train_loss 0.560 val_loss 0.566 val_auc_score 0.810\n",
      "----End of step 0:00:49.583873\n",
      "train_loss 0.545 val_loss 0.564 val_auc_score 0.796\n",
      "----End of step 0:00:50.385066\n",
      "train_loss 0.533 val_loss 0.539 val_auc_score 0.819\n",
      "----End of step 0:00:50.349767\n",
      "train_loss 0.522 val_loss 0.579 val_auc_score 0.839\n",
      "----End of step 0:00:49.891528\n",
      "train_loss 0.512 val_loss 0.598 val_auc_score 0.815\n",
      "----End of step 0:00:48.964416\n",
      "train_loss 0.504 val_loss 0.520 val_auc_score 0.846\n",
      "----End of step 0:00:50.726136\n",
      "train_loss 0.493 val_loss 0.531 val_auc_score 0.821\n",
      "----End of step 0:00:49.979191\n",
      "train_loss 0.487 val_loss 0.529 val_auc_score 0.843\n",
      "----End of step 0:00:49.717923\n",
      "train_loss 0.474 val_loss 0.514 val_auc_score 0.859\n",
      "----End of step 0:00:50.302188\n",
      "train_loss 0.468 val_loss 0.542 val_auc_score 0.855\n",
      "----End of step 0:00:49.694980\n",
      "train_loss 0.455 val_loss 0.506 val_auc_score 0.857\n",
      "----End of step 0:00:49.208765\n",
      "train_loss 0.449 val_loss 0.507 val_auc_score 0.859\n",
      "----End of step 0:00:49.974855\n",
      "train_loss 0.441 val_loss 0.498 val_auc_score 0.860\n",
      "----End of step 0:00:49.692447\n",
      "train_loss 0.436 val_loss 0.498 val_auc_score 0.861\n",
      "----End of step 0:00:48.962630\n",
      "train_loss 0.603 val_loss 0.683 val_auc_score 0.769\n",
      "----End of step 0:00:50.051770\n",
      "train_loss 0.563 val_loss 0.567 val_auc_score 0.818\n",
      "----End of step 0:00:50.011022\n",
      "train_loss 0.545 val_loss 0.582 val_auc_score 0.788\n",
      "----End of step 0:00:49.393958\n",
      "train_loss 0.533 val_loss 0.536 val_auc_score 0.824\n",
      "----End of step 0:00:49.922565\n",
      "train_loss 0.522 val_loss 0.546 val_auc_score 0.820\n",
      "----End of step 0:00:49.703841\n",
      "train_loss 0.512 val_loss 0.571 val_auc_score 0.816\n",
      "----End of step 0:00:48.992357\n",
      "train_loss 0.506 val_loss 0.533 val_auc_score 0.828\n",
      "----End of step 0:00:49.723141\n",
      "train_loss 0.494 val_loss 0.541 val_auc_score 0.850\n",
      "----End of step 0:00:50.333830\n",
      "train_loss 0.485 val_loss 0.549 val_auc_score 0.852\n",
      "----End of step 0:00:49.823740\n",
      "train_loss 0.476 val_loss 0.516 val_auc_score 0.848\n",
      "----End of step 0:00:49.341219\n",
      "train_loss 0.468 val_loss 0.504 val_auc_score 0.851\n",
      "----End of step 0:00:49.968513\n",
      "train_loss 0.460 val_loss 0.498 val_auc_score 0.851\n",
      "----End of step 0:00:49.087347\n",
      "train_loss 0.451 val_loss 0.489 val_auc_score 0.857\n",
      "----End of step 0:00:49.797489\n",
      "train_loss 0.444 val_loss 0.502 val_auc_score 0.858\n",
      "----End of step 0:00:49.574423\n",
      "train_loss 0.441 val_loss 0.495 val_auc_score 0.860\n",
      "----End of step 0:00:49.994406\n",
      "train_loss 0.605 val_loss 0.657 val_auc_score 0.790\n",
      "----End of step 0:00:48.681736\n",
      "train_loss 0.562 val_loss 0.547 val_auc_score 0.822\n",
      "----End of step 0:00:50.312926\n",
      "train_loss 0.545 val_loss 0.567 val_auc_score 0.804\n",
      "----End of step 0:00:50.585696\n",
      "train_loss 0.534 val_loss 0.670 val_auc_score 0.790\n",
      "----End of step 0:00:50.024604\n",
      "train_loss 0.523 val_loss 0.536 val_auc_score 0.828\n",
      "----End of step 0:00:48.825689\n",
      "train_loss 0.513 val_loss 0.550 val_auc_score 0.822\n",
      "----End of step 0:00:49.609745\n",
      "train_loss 0.506 val_loss 0.587 val_auc_score 0.829\n",
      "----End of step 0:00:49.712028\n",
      "train_loss 0.497 val_loss 0.518 val_auc_score 0.851\n",
      "----End of step 0:00:49.596466\n",
      "train_loss 0.486 val_loss 0.510 val_auc_score 0.860\n",
      "----End of step 0:00:49.477990\n",
      "train_loss 0.477 val_loss 0.495 val_auc_score 0.852\n",
      "----End of step 0:00:49.474797\n",
      "train_loss 0.465 val_loss 0.498 val_auc_score 0.856\n",
      "----End of step 0:00:49.467453\n",
      "train_loss 0.455 val_loss 0.494 val_auc_score 0.855\n",
      "----End of step 0:00:50.873074\n",
      "train_loss 0.447 val_loss 0.496 val_auc_score 0.859\n",
      "----End of step 0:00:49.790757\n",
      "train_loss 0.442 val_loss 0.495 val_auc_score 0.860\n",
      "----End of step 0:00:49.632720\n",
      "train_loss 0.437 val_loss 0.489 val_auc_score 0.860\n",
      "----End of step 0:00:49.474583\n",
      "train_loss 0.603 val_loss 0.793 val_auc_score 0.766\n",
      "----End of step 0:00:49.252151\n",
      "train_loss 0.562 val_loss 0.629 val_auc_score 0.803\n",
      "----End of step 0:00:47.929292\n",
      "train_loss 0.547 val_loss 0.571 val_auc_score 0.820\n",
      "----End of step 0:00:47.752241\n",
      "train_loss 0.532 val_loss 0.558 val_auc_score 0.809\n",
      "----End of step 0:00:48.718793\n",
      "train_loss 0.524 val_loss 0.557 val_auc_score 0.800\n",
      "----End of step 0:00:48.686449\n",
      "train_loss 0.511 val_loss 0.662 val_auc_score 0.813\n",
      "----End of step 0:00:49.143524\n",
      "train_loss 0.506 val_loss 0.536 val_auc_score 0.835\n",
      "----End of step 0:00:48.235659\n",
      "train_loss 0.495 val_loss 0.524 val_auc_score 0.843\n",
      "----End of step 0:00:48.326757\n",
      "train_loss 0.486 val_loss 0.524 val_auc_score 0.839\n",
      "----End of step 0:00:47.939937\n",
      "train_loss 0.477 val_loss 0.513 val_auc_score 0.850\n",
      "----End of step 0:00:49.421294\n",
      "train_loss 0.465 val_loss 0.512 val_auc_score 0.844\n",
      "----End of step 0:00:48.233125\n",
      "train_loss 0.458 val_loss 0.517 val_auc_score 0.859\n",
      "----End of step 0:00:56.058588\n",
      "train_loss 0.451 val_loss 0.514 val_auc_score 0.862\n",
      "----End of step 0:00:51.087802\n",
      "train_loss 0.444 val_loss 0.500 val_auc_score 0.860\n",
      "----End of step 0:00:47.974575\n",
      "train_loss 0.442 val_loss 0.501 val_auc_score 0.863\n",
      "----End of step 0:00:47.901542\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.25).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_25_1_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_0_25_full_depth'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss 0.581 val_loss 0.630 val_auc_score 0.778\n",
      "----End of step 0:00:43.337208\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    d = depths[4]\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.5, \n",
    "                     inverted_residual_setting1=d[0], \n",
    "                     inverted_residual_setting2=d[1]).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_4_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_0_5_4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_5_full_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.5).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_5_1_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_0_5_full_depth'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0_75_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    d = depths[4]\n",
    "    model = resnet18(num_classes=1000, block=depthwise_block, width_mult=0.75, \n",
    "                     inverted_residual_setting1=d[0], \n",
    "                     inverted_residual_setting2=d[1]).cuda()\n",
    "    load_model(model, '/home/rimmanni/imagenet/res_depth_net_0_75_4_iter20.pth')\n",
    "    model.classifier = nn.Linear(in_features=512, out_features=1, bias=True).cuda()\n",
    "    optimizer = create_optimizer(model, 0.01)\n",
    "    score, t = train_triangular_policy(model, optimizer, train_loader, valid_loader, valid_dataset,\n",
    "                                       loss_fn=F.binary_cross_entropy_with_logits, \n",
    "                                       dataset='mura', binary=True, max_lr=0.01, epochs=15)\n",
    "    \n",
    "    data.append([score, t, 'mura', 'resnet_0_75_4'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['score', 'time', 'dataset', 'model']\n",
    "df = pd.DataFrame(data=data, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mura_resnet.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
